{
  "metadata": {
    "generated_at": "2025-08-12T23:58:22.624671",
    "total_questions": 79,
    "total_comments": 2,
    "version": "3.0-robust-extraction",
    "extraction_method": "robust_boundary_detection"
  },
  "questions": [
    {
      "id": "Q1_1",
      "number": "1",
      "description": "Your company has decided to make a major revision of their API in order to create better experiences for their developers. They need to keep the old version of the API available and deployable, while allowing new customers and testers to try out the new API. They want to keep the same SSL and DNS records in place to serve both APIs. What should they do?",
      "options": {
        "A": "Configure a new load balancer for the new version of the API",
        "B": "ReConfigure old clients to use a new endpoint for the new API",
        "C": "Have the old API forward traffic to the new API based on the path",
        "D": "Use separate backend pools for each API path behind the load balancer"
      },
      "introductory_info": "",
      "answers": {
        "community": "B",
        "highly_voted": "",
        "most_recent": "",
        "claude": "B"
      },
      "claude_reasoning": "No clear GCP pattern found. Selected B randomly to avoid bias. Manual review needed.",
      "metadata": {
        "topic": "General",
        "page": 1,
        "source": "Questions_1.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q5_2",
      "number": "2",
      "description": "Your company plans to migrate a multi-petabyte data set to the cloud. The data set must be available 24hrs a day. Your business analysts have experience only with using a SQL interface. How should you store the data to optimize it for ease of analysis?",
      "options": {
        "A": "Load data into Google BigQuery",
        "B": "Insert data into Google Cloud SQL",
        "C": "Put flat files into Google Cloud Storage",
        "D": "Stream data into Google Cloud Datastore"
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "Selected A because it uses GCP services (bigquery): load data into google bigquery...",
      "metadata": {
        "topic": "General",
        "page": 5,
        "source": "Questions_1.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q8_3",
      "number": "3",
      "description": "The operations manager asks you for a list of recommended practices that she should consider when migrating a J2EE application to the cloud. Which three practices should you recommend? (Choose three.)",
      "options": {
        "A": "Port the application code to run on Google App Engine",
        "B": "Integrate Cloud Dataflow into the application to capture real-time metrics",
        "C": "Instrument the application with a monitoring tool like Stackdriver Debugger",
        "D": "Select an automation framework to reliably provision the cloud infrastructure",
        "E": "Deploy a continuous integration tool with automated testing in a staging environment",
        "F": "Migrate from MySQL to a managed NoSQL database like Google Cloud Datastore or Bigtable"
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "Selected A because it uses GCP services (app engine): port the application code to run on google app engine...",
      "metadata": {
        "topic": "General",
        "page": 8,
        "source": "Questions_1.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q12_4",
      "number": "4",
      "description": "A news feed web service has the following code running on Google App Engine. During peak load, users report that they can see news articles they already viewed. What is the most likely cause of this problem?",
      "options": {
        "A": "The session variable is local to just a single instance",
        "B": "The session variable is being overwritten in Cloud Datastore",
        "C": "The URL of the API needs to be modified to prevent caching",
        "D": "The HTTP Expires header needs to be set to -1 stop caching"
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "Option A best matches question context: the session variable is local to just a single instance...",
      "metadata": {
        "topic": "General",
        "page": 12,
        "source": "Questions_1.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q15_5",
      "number": "5",
      "description": "An application development team believes their current logging tool will not meet their needs for their new cloud-based product. They want a better tool to capture errors and help them analyze their historical log data. You want to help them find a solution that meets their needs. What should you do?",
      "options": {
        "A": "Direct them to download and install the Google StackDriver logging agent",
        "B": "Send them a list of online resources about logging best practices",
        "C": "Help them define their requirements and assess viable logging tools",
        "D": "Help them upgrade their current tool to take advantage of any new features"
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "GCP best practice suggests A: direct them to download and install the google stackdriver logging agent...",
      "metadata": {
        "topic": "General",
        "page": 15,
        "source": "Questions_1.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q18_71",
      "number": "71",
      "description": "Your company is running a stateless application on a Compute Engine instance. The application is used heavily during regular business hours and lightly outside of business hours. Users are reporting that the application is slow during peak hours. You need to optimize the application's performance. What should you do?",
      "options": {
        "A": "Create a snapshot of the existing disk. Create an instance template from the snapshot. Create an autoscaled managed instance group from the instance template.",
        "B": "Create a snapshot of the existing disk. Create a custom image from the snapshot. Create an autoscaled managed instance group from the custom image.",
        "C": "Create a custom image from the existing disk. Create an instance template from the custom image. Create an autoscaled managed instance group from the instance template.",
        "D": "Create an instance template from the existing disk. Create a custom image from the instance template. Create an autoscaled managed instance group from the custom image."
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "Option A best matches question context: create a snapshot of the existing disk. create an instance template from the snapshot. create an autoscaled managed instance group from the instance t...",
      "metadata": {
        "topic": "General",
        "page": 18,
        "source": "Questions_10.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q20_72",
      "number": "72",
      "description": "Your web application has several VM instances running within a VPC. You want to restrict communications between instances to only the paths and ports you authorize, but you don't want to rely on static IP addresses or subnets because the app can autoscale. How should you restrict communications?",
      "options": {
        "A": "Use separate VPCs to restrict traffic",
        "B": "Use Krewall rules based on network tags attached to the compute instances",
        "C": "Use Cloud DNS and only allow connections from authorized hostnames",
        "D": "Use service accounts and Configure the web application to authorize particular service accounts to have access"
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "GCP best practice suggests A: use separate vpcs to restrict traffic...",
      "metadata": {
        "topic": "General",
        "page": 20,
        "source": "Questions_10.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q2_73",
      "number": "73",
      "description": "You are using Cloud SQL as the database backend for a large CRM deployment. You want to scale as usage increases and ensure that you don't run out of storage, maintain 75% CPU usage cores, and keep replication lag below 60 seconds. What are the correct steps to meet your requirements?",
      "options": {
        "A": "1. Enable automatic storage increase for the instance. 2. Create a Stackdriver alert when CPU usage exceeds 75%, and change the instance type to reduce CPU usage. 3. Create a Stackdriver alert for replication lag, and shard the database to reduce replication time.",
        "B": "1. Enable automatic storage increase for the instance. 2. Change the instance type to a 32-core machine type to keep CPU usage below 75%. 3. Create a Stackdriver alert for replication lag, and deploy memcache to reduce load on the master.",
        "C": "1. Create a Stackdriver alert when storage exceeds 75%, and increase the available storage on the instance to create more space. 2. Deploy memcached to reduce CPU load. 3. Change the instance type to a 32-core machine type to reduce replication lag.",
        "D": "1. Create a Stackdriver alert when storage exceeds 75%, and increase the available storage on the instance to create more space. 2. Deploy memcached to reduce CPU load. 3. Create a Stackdriver alert for replication lag, and change the instance type to a 32-core machine type to"
      },
      "introductory_info": "",
      "answers": {
        "community": "C",
        "highly_voted": "",
        "most_recent": "",
        "claude": "C"
      },
      "claude_reasoning": "No clear GCP pattern found. Selected C randomly to avoid bias. Manual review needed.",
      "metadata": {
        "topic": "General",
        "page": 2,
        "source": "Questions_11.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q6_74",
      "number": "74",
      "description": "You are tasked with building an online analytical processing (OLAP) marketing analytics and reporting tool. This requires a relational database that can operate on hundreds of terabytes of data. What is the Google-recommended tool for such applications?",
      "options": {
        "A": "Cloud Spanner, because it is globally distributed",
        "B": "Cloud SQL, because it is a fully managed relational database",
        "C": "Cloud Firestore, because it offers real-time synchronization across devices",
        "D": "BigQuery, because it is designed for large-scale processing of tabular data"
      },
      "introductory_info": "",
      "answers": {
        "community": "B",
        "highly_voted": "",
        "most_recent": "",
        "claude": "B"
      },
      "claude_reasoning": "Selected B because it uses GCP services (cloud sql): cloud sql, because it is a fully managed relational database...",
      "metadata": {
        "topic": "General",
        "page": 6,
        "source": "Questions_11.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q8_75",
      "number": "75",
      "description": "You have deployed an application to Google Kubernetes Engine (GKE), and are using the Cloud SQL proxy container to make the Cloud SQL database available to the services running on Kubernetes. You are notiKed that the application is reporting database connection issues. Your company policies require a post- mortem. What should you do?",
      "options": {
        "A": "Use gcloud sql instances restart.",
        "B": "Validate that the Service Account used by the Cloud SQL proxy container still has the Cloud Build Editor role.",
        "C": "In the GCP Console, navigate to Stackdriver Logging. Consult logs for (GKE) and Cloud SQL.",
        "D": "In the GCP Console, navigate to Cloud SQL. Restore the latest backup. Use kubectl to restart all pods."
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "Selected A because it uses GCP services (cloud sql): use gcloud sql instances restart....",
      "metadata": {
        "topic": "General",
        "page": 8,
        "source": "Questions_11.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q10_76",
      "number": "76",
      "description": "Your company pushes batches of sensitive transaction data from its application server VMs to Cloud Pub/Sub for processing and storage. What is the Google- recommended way for your application to authenticate to the required Google Cloud services?",
      "options": {
        "A": "Ensure that VM service accounts are granted the appropriate Cloud Pub/Sub IAM roles.",
        "B": "Ensure that VM service accounts do not have access to Cloud Pub/Sub, and use VM access scopes to grant the appropriate Cloud Pub/Sub IAM roles.",
        "C": "Generate an OAuth2 access token for accessing Cloud Pub/Sub, encrypt it, and store it in Cloud Storage for access from each VM.",
        "D": "Create a gateway to Cloud Pub/Sub using a Cloud Function, and grant the Cloud Function service account the appropriate Cloud Pub/Sub IAM roles."
      },
      "introductory_info": "",
      "answers": {
        "community": "C",
        "highly_voted": "",
        "most_recent": "",
        "claude": "C"
      },
      "claude_reasoning": "Selected C because it uses GCP services (cloud storage, pub/sub): generate an oauth2 access token for accessing cloud pub/sub, encrypt it, and store it in cloud storage for access from e...",
      "metadata": {
        "topic": "General",
        "page": 10,
        "source": "Questions_11.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q13_77",
      "number": "77",
      "description": "You want to establish a Compute Engine application in a single VPC across two regions. The application must communicate over VPN to an on- premises network. How should you deploy the VPN?",
      "options": {
        "A": "Use VPC Network Peering between the VPC and the on-premises network.",
        "B": "Expose the VPC to the on-premises network using IAM and VPC Sharing.",
        "C": "Create a global Cloud VPN Gateway with VPN tunnels from each region to the on-premises peer gateway.",
        "D": "Deploy Cloud VPN Gateway in each region. Ensure that each region has at least one VPN tunnel to the on-premises peer gateway."
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "GCP best practice suggests A: use vpc network peering between the vpc and the on-premises network....",
      "metadata": {
        "topic": "General",
        "page": 13,
        "source": "Questions_11.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q16_78",
      "number": "78",
      "description": "Your applications will be writing their logs to BigQuery for analysis. Each application should have its own table. Any logs older than 45 days should be removed. You want to optimize storage and follow Google-recommended practices. What should you do?",
      "options": {
        "A": "Configure the expiration time for your tables at 45 days",
        "B": "Make the tables time-partitioned, and Configure the partition expiration at 45 days",
        "C": "Rely on BigQuery's default behavior to prune application logs older than 45 days",
        "D": "Create a script that uses the BigQuery command line tool (bq) to remove records older than 45 days"
      },
      "introductory_info": "",
      "answers": {
        "community": "C",
        "highly_voted": "",
        "most_recent": "",
        "claude": "C"
      },
      "claude_reasoning": "BigQuery is optimal for large-scale data analytics. C: rely on bigquery's default behavior to prune application logs older than 45 days...",
      "metadata": {
        "topic": "General",
        "page": 16,
        "source": "Questions_11.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q18_79",
      "number": "79",
      "description": "You want your Google Kubernetes Engine cluster to automatically add or remove nodes based on CPU load. What should you do?",
      "options": {
        "A": "Configure a HorizontalPodAutoscaler with a target CPU usage. Enable the Cluster Autoscaler from the GCP Console.",
        "B": "Configure a HorizontalPodAutoscaler with a target CPU usage. Enable autoscaling on the managed instance group for the cluster using the gcloud command.",
        "C": "Create a deployment and set the maxUnavailable and maxSurge properties. Enable the Cluster Autoscaler using the gcloud command.",
        "D": "Create a deployment and set the maxUnavailable and maxSurge properties. Enable autoscaling on the cluster managed instance group from the GCP Console."
      },
      "introductory_info": "",
      "answers": {
        "community": "B",
        "highly_voted": "",
        "most_recent": "",
        "claude": "B"
      },
      "claude_reasoning": "Option B best matches question context: configure a horizontalpodautoscaler with a target cpu usage. enable autoscaling on the managed instance group for the cluster using the gcloud command...",
      "metadata": {
        "topic": "General",
        "page": 18,
        "source": "Questions_11.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q9_83",
      "number": "83",
      "description": "Your BigQuery project has several users. For audit purposes, you need to see how many queries each user ran in the last month. What should you",
      "options": {
        "A": "Connect Google Data Studio to BigQuery. Create a dimension for the users and a metric for the amount of queries per user.",
        "B": "In the BigQuery interface, execute a query on the JOBS table to get the required information.",
        "C": "Use 'bq show' to list all jobs. Per job, use 'bq ls' to list job information and get the required information.",
        "D": "Use Cloud Audit Logging to view Cloud Audit Logs, and create a Klter on the query operation to get the required information."
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "BigQuery is optimal for large-scale data analytics. A: connect google data studio to bigquery. create a dimension for the users and a metric for the amount...",
      "metadata": {
        "topic": "General",
        "page": 9,
        "source": "Questions_12.pdf",
        "confidence": 0.7000000000000001,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q12_84",
      "number": "84",
      "description": "You want to automate the creation of a managed instance group. The VMs have many OS package dependencies. You want to minimize the startup time for new VMs in the instance group. What should you do?",
      "options": {
        "A": "Use Terraform to create the managed instance group and a startup script to install the OS package dependencies.",
        "B": "Create a custom VM image with all OS package dependencies. Use Deployment Manager to create the managed instance group with the VM image.",
        "C": "Use Puppet to create the managed instance group and install the OS package dependencies.",
        "D": "Use Deployment Manager to create the managed instance group and Ansible to install the OS package dependencies."
      },
      "introductory_info": "",
      "answers": {
        "community": "D",
        "highly_voted": "",
        "most_recent": "",
        "claude": "D"
      },
      "claude_reasoning": "No clear GCP pattern found. Selected D randomly to avoid bias. Manual review needed.",
      "metadata": {
        "topic": "General",
        "page": 12,
        "source": "Questions_12.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q15_85",
      "number": "85",
      "description": "Your company captures all web traffic data in Google Analytics 360 and stores it in BigQuery. Each country has its own dataset. Each dataset has multiple tables. You want analysts from each country to be able to see and query only the data for their respective countries. How should you Configure the access rights?",
      "options": {
        "A": "Create a group per country. Add analysts to their respective country-groups. Create a single group 'all_analysts', and add all country-groups as members. Grant the 'all_analysts' group the IAM role of BigQuery jobUser. Share the appropriate dataset with view access with each respective analyst country-group.",
        "B": "Create a group per country. Add analysts to their respective country-groups. Create a single group 'all_analysts', and add all country-groups as members. Grant the 'all_analysts' group the IAM role of BigQuery jobUser. Share the appropriate tables with view access with each",
        "C": "Create a group per country. Add analysts to their respective country-groups. Create a single group 'all_analysts', and add all country-groups as members. Grant the 'all_analysts' group the IAM role of BigQuery dataViewer. Share the appropriate dataset with view access with each respective analyst country- group.",
        "D": "Create a group per country. Add analysts to their respective country-groups. Create a single group 'all_analysts', and add all country-groups as members. Grant the 'all_analysts' group the IAM role of BigQuery dataViewer. Share the appropriate table with view access with each respective analyst country-group."
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "BigQuery is optimal for large-scale data analytics. A: create a group per country. add analysts to their respective country-groups. create a single group '...",
      "metadata": {
        "topic": "General",
        "page": 15,
        "source": "Questions_12.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q19_86",
      "number": "86",
      "description": "You have been engaged by your client to lead the migration of their application infrastructure to GCP. One of their current problems is that the on- premises high performance SAN is requiring frequent and expensive upgrades to keep up with the variety of workloads that are identiKed as follows: 20 TB of log archives retained for legal reasons; 500 GB of VM boot/data volumes and templates; 500 GB of image thumbnails; 200 GB of customer session state data that allows customers to restart sessions even if off-line for several days. Which of the following best re^ects your recommendations for a cost-effective storage allocation?",
      "options": {
        "A": "Local SSD for customer session state data. Lifecycle-managed Cloud Storage for log archives, thumbnails, and VM boot/data volumes.",
        "B": "Memcache backed by Cloud Datastore for the customer session state data. Lifecycle-managed Cloud Storage for log archives, thumbnails, and VM boot/data volumes.",
        "C": "Memcache backed by Cloud SQL for customer session state data. Assorted local SSD-backed instances for VM boot/data volumes. Cloud Storage for log archives and thumbnails.",
        "D": "Memcache backed by Persistent Disk SSD storage for customer session state data. Assorted local SSD-backed instances for VM boot/data volumes. Cloud Storage for log archives and thumbnails."
      },
      "introductory_info": "",
      "answers": {
        "community": "B",
        "highly_voted": "",
        "most_recent": "",
        "claude": "B"
      },
      "claude_reasoning": "Selected B because it uses GCP services (cloud storage): memcache backed by cloud datastore for the customer session state data. lifecycle-managed cloud storage for log archives...",
      "metadata": {
        "topic": "General",
        "page": 19,
        "source": "Questions_12.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q5_88",
      "number": "88",
      "description": "You are using Cloud CDN to deliver static HTTP(S) website content hosted on a Compute Engine instance group. You want to improve the cache What should you do?",
      "options": {
        "A": "Customize the cache keys to omit the protocol from the key.",
        "B": "Shorten the expiration time of the cached objects.",
        "C": "Make sure the HTTP(S) header ג€Cache-Regionג€ points to the closest region of your users.",
        "D": "Replicate the static content in a Cloud Storage bucket. Point CloudCDN toward a load balancer on that bucket."
      },
      "introductory_info": "",
      "answers": {
        "community": "D",
        "highly_voted": "",
        "most_recent": "",
        "claude": "D"
      },
      "claude_reasoning": "Selected D because it uses GCP services (cloud storage): replicate the static content in a cloud storage bucket. point cloudcdn toward a load balancer on that bucket....",
      "metadata": {
        "topic": "General",
        "page": 5,
        "source": "Questions_13.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q10_90",
      "number": "90",
      "description": "You have an App Engine application that needs to be updated. You want to test the update with production traffic before replacing the current application version. What should you do?",
      "options": {
        "A": "Deploy the update using the Instance Group Updater to create a partial rollout, which allows for canary testing.",
        "B": "Deploy the update as a new version in the App Engine application, and split traffic between the new and current versions.",
        "C": "Deploy the update in a new VPC, and use Google's global HTTP load balancing to split traffic between the update and current applications.",
        "D": "Deploy the update as a new App Engine application, and use Google's global HTTP load balancing to split traffic between the new and current applications."
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "Option A best matches question context: deploy the update using the instance group updater to create a partial rollout, which allows for canary testing....",
      "metadata": {
        "topic": "General",
        "page": 10,
        "source": "Questions_13.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q12_91",
      "number": "91",
      "description": "All Compute Engine instances in your VPC should be able to connect to an Active Directory server on speciKc ports. Any other traffic emerging from your instances is not allowed. You want to enforce this using VPC Krewall rules. How should you Configure the Krewall rules?",
      "options": {
        "A": "Create an egress rule with priority 1000 to deny all traffic for all instances. Create another egress rule with priority 100 to allow the Active Directory traffic for all instances.",
        "B": "Create an egress rule with priority 100 to deny all traffic for all instances. Create another egress rule with priority 1000 to allow the Active Directory traffic for all instances.",
        "C": "Create an egress rule with priority 1000 to allow the Active Directory traffic. Rely on the implied deny egress rule with priority 100 to block all traffic for all instances."
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "Option A best matches question context: create an egress rule with priority 1000 to deny all traffic for all instances. create another egress rule with priority 100 to allow the active direc...",
      "metadata": {
        "topic": "General",
        "page": 12,
        "source": "Questions_13.pdf",
        "confidence": 0.7000000000000001,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q17_93",
      "number": "93",
      "description": "A development team at your company has created a dockerized HTTPS web application. You need to deploy the application on Google Kubernetes Engine (GKE) and make sure that the application scales automatically. How should you deploy to GKE?",
      "options": {
        "A": "Use the Horizontal Pod Autoscaler and enable cluster autoscaling. Use an Ingress resource to load-balance the HTTPS traffic.",
        "B": "Use the Horizontal Pod Autoscaler and enable cluster autoscaling on the Kubernetes cluster. Use a Service resource of type LoadBalancer to load-balance the HTTPS traffic.",
        "C": "Enable autoscaling on the Compute Engine instance group. Use an Ingress resource to load-balance the HTTPS traffic.",
        "D": "Enable autoscaling on the Compute Engine instance group. Use a Service resource of type LoadBalancer to load-balance the HTTPS traffic."
      },
      "introductory_info": "",
      "answers": {
        "community": "B",
        "highly_voted": "",
        "most_recent": "",
        "claude": "B"
      },
      "claude_reasoning": "Selected B because it uses GCP services (kubernetes): use the horizontal pod autoscaler and enable cluster autoscaling on the kubernetes cluster. use a service resource of ty...",
      "metadata": {
        "topic": "General",
        "page": 17,
        "source": "Questions_13.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q20_94",
      "number": "94",
      "description": "You need to design a solution for global load balancing based on the URL path being requested. You need to ensure operations reliability and end- to-end in- transit encryption based on Google best practices. What should you do?",
      "options": {
        "A": "Create a cross-region load balancer with URL Maps.",
        "B": "Create an HTTPS load balancer with URL Maps.",
        "C": "Create appropriate instance groups and instances. Configure SSL proxy load balancing.",
        "D": "Create a global forwarding rule. Configure SSL proxy load balancing."
      },
      "introductory_info": "",
      "answers": {
        "community": "C",
        "highly_voted": "",
        "most_recent": "",
        "claude": "C"
      },
      "claude_reasoning": "Option C best matches question context: create appropriate instance groups and instances. configure ssl proxy load balancing....",
      "metadata": {
        "topic": "General",
        "page": 20,
        "source": "Questions_13.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q3_95",
      "number": "95",
      "description": "You have an application that makes HTTP requests to Cloud Storage. Occasionally the requests fail with HTTP status codes of 5xx and 429. How should you handle these types of errors?",
      "options": {
        "A": "Use gRPC instead of HTTP for better performance.",
        "B": "Implement retry logic using a truncated exponential backoff strategy.",
        "C": "Make sure the Cloud Storage bucket is multi-regional for geo-redundancy.",
        "D": "Monitor https://status.cloud.google.com/feed.atom and only make requests if Cloud Storage is not reporting an incident."
      },
      "introductory_info": "",
      "answers": {
        "community": "C",
        "highly_voted": "",
        "most_recent": "",
        "claude": "C"
      },
      "claude_reasoning": "Cloud Storage offers lifecycle management and scalability. C: make sure the cloud storage bucket is multi-regional for geo-redundancy....",
      "metadata": {
        "topic": "General",
        "page": 3,
        "source": "Questions_14.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q10_98",
      "number": "98",
      "description": "Your company acquired a healthcare startup and must retain its customers' medical information for up to 4 more years, depending on when it was created. Your corporate policy is to securely retain this data, and then delete it as soon as regulations allow. Which approach should you take?",
      "options": {
        "A": "Store the data in Google Drive and manually delete records as they expire.",
        "B": "Anonymize the data using the Cloud Data Loss Prevention API and store it indeKnitely.",
        "C": "Store the data in Cloud Storage and use lifecycle management to delete Kles when they expire.",
        "D": "Store the data in Cloud Storage and run a nightly batch script that deletes all expired data."
      },
      "introductory_info": "",
      "answers": {
        "community": "C",
        "highly_voted": "",
        "most_recent": "",
        "claude": "C"
      },
      "claude_reasoning": "Selected C because it uses GCP services (cloud storage): store the data in cloud storage and use lifecycle management to delete kles when they expire....",
      "metadata": {
        "topic": "General",
        "page": 10,
        "source": "Questions_14.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q12_99",
      "number": "99",
      "description": "You are deploying a PHP App Engine Standard service with Cloud SQL as the backend. You want to minimize the number of queries to the What should you do?",
      "options": {
        "A": "Set the memcache service level to dedicated. Create a key from the hash of the query, and return database values from memcache before issuing a query to Cloud SQL.",
        "B": "Set the memcache service level to dedicated. Create a cron task that runs every minute to populate the cache with keys containing query results.",
        "C": "Set the memcache service level to shared. Create a cron task that runs every minute to save all expected queries to a key called ג€cached_queriesג€.",
        "D": "Set the memcache service level to shared. Create a key called ג€cached_queriesג€, and return database values from the key before using a query to Cloud SQL."
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "Selected A because it uses GCP services (cloud sql): set the memcache service level to dedicated. create a key from the hash of the query, and return database values from me...",
      "metadata": {
        "topic": "General",
        "page": 12,
        "source": "Questions_14.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q14_100",
      "number": "100",
      "description": "You need to ensure reliability for your application and operations by supporting reliable task scheduling for compute on GCP. Leveraging Google best practices, what should you do?",
      "options": {
        "A": "Using the Cron service provided by App Engine, publish messages directly to a message-processing utility service running on Compute Engine instances.",
        "B": "Using the Cron service provided by App Engine, publish messages to a Cloud Pub/Sub topic. Subscribe to that topic using a message- processing utility service running on Compute Engine instances.",
        "C": "Using the Cron service provided by Google Kubernetes Engine (GKE), publish messages directly to a message-processing utility service running on Compute Engine instances.",
        "D": "Using the Cron service provided by GKE, publish messages to a Cloud Pub/Sub topic. Subscribe to that topic using a message-processing utility service running on Compute Engine instances."
      },
      "introductory_info": "",
      "answers": {
        "community": "B",
        "highly_voted": "",
        "most_recent": "",
        "claude": "B"
      },
      "claude_reasoning": "Selected B because it uses GCP services (compute engine, pub/sub, app engine): using the cron service provided by app engine, publish messages to a cloud pub/sub topic. subscribe to that topic using ...",
      "metadata": {
        "topic": "General",
        "page": 14,
        "source": "Questions_14.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q16_101",
      "number": "101",
      "description": "Your company is building a new architecture to support its data-centric business focus. You are responsible for setting up the network. Your company's mobile and web-facing applications will be deployed on-premises, and all data analysis will be conducted in GCP. The plan is to process and load 7 years of archived .csv Kles totaling 900 TB of data and then continue loading 10 TB of data daily. You currently have an existing 100-MB internet connection. What actions will meet your company's needs?",
      "options": {
        "A": "Compress and upload both archived Kles and Kles uploaded daily using the gsutil ג€\"m option.",
        "B": "Lease a Transfer Appliance, upload archived Kles to it, and send it to Google to transfer archived data to Cloud Storage. Establish a connection with Google using a Dedicated Interconnect or Direct Peering connection and use it to upload Kles daily.",
        "C": "Lease a Transfer Appliance, upload archived Kles to it, and send it to Google to transfer archived data to Cloud Storage. Establish one Cloud VPN Tunnel to VPC networks over the public internet, and compress and upload Kles daily using the gsutil ג€\"m option.",
        "D": "Lease a Transfer Appliance, upload archived Kles to it, and send it to Google to transfer archived data to Cloud Storage. Establish a Cloud VPN Tunnel to VPC networks over the public internet, and compress and upload Kles daily."
      },
      "introductory_info": "",
      "answers": {
        "community": "C",
        "highly_voted": "",
        "most_recent": "",
        "claude": "C"
      },
      "claude_reasoning": "GCP best practice suggests C: lease a transfer appliance, upload archived kles to it, and send it to google to transfer archived d...",
      "metadata": {
        "topic": "General",
        "page": 16,
        "source": "Questions_14.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q19_102",
      "number": "102",
      "description": "You are developing a globally scaled frontend for a legacy streaming backend data API. This API expects events in strict chronological order with no repeat data for proper processing. Which products should you deploy to ensure guaranteed-once FIFO (Krst-in, Krst-out) delivery of data?",
      "options": {
        "A": "Cloud Pub/Sub alone",
        "B": "Cloud Pub/Sub to Cloud Dataflow",
        "C": "Cloud Pub/Sub to Stackdriver",
        "D": "Cloud Pub/Sub to Cloud SQL"
      },
      "introductory_info": "",
      "answers": {
        "community": "B",
        "highly_voted": "",
        "most_recent": "",
        "claude": "B"
      },
      "claude_reasoning": "Selected B because it uses GCP services (pub/sub, dataflow): cloud pub/sub to cloud dataflow...",
      "metadata": {
        "topic": "General",
        "page": 19,
        "source": "Questions_14.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q2_103",
      "number": "103",
      "description": "Your company is planning to perform a lift and shift migration of their Linux RHEL 6.5+ virtual machines. The virtual machines are running in an on-premises VMware environment. You want to migrate them to Compute Engine following Google-recommended practices. What should you do?",
      "options": {
        "A": "1. define a migration plan based on the list of the applications and their dependencies. 2. Migrate all virtual machines into Compute Engine individually with Migrate for Compute Engine.",
        "B": "1. Perform an assessment of virtual machines running in the current VMware environment. 2. Create images of all disks. Import disks on Compute Engine. 3. Create standard virtual machines where the boot disks are the ones you have imported.",
        "C": "1. Perform an assessment of virtual machines running in the current VMware environment. 2. define a migration plan, prepare a Migrate for Compute Engine migration RunBook, and execute the migration.",
        "D": "1. Perform an assessment of virtual machines running in the current VMware environment. 2. Install a third-party agent on all selected virtual machines. 3. Migrate all virtual machines into Compute Engine."
      },
      "introductory_info": "",
      "answers": {
        "community": "B",
        "highly_voted": "",
        "most_recent": "",
        "claude": "B"
      },
      "claude_reasoning": "Selected B because it uses GCP services (compute engine): 1. perform an assessment of virtual machines running in the current vmware environment. 2. create images of all disks. i...",
      "metadata": {
        "topic": "General",
        "page": 2,
        "source": "Questions_15.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q4_104",
      "number": "104",
      "description": "You need to deploy an application to Google Cloud. The application receives traffic via TCP and reads and writes data to the Klesystem. The application does not support horizontal scaling. The application process requires full control over the data on the Kle system because concurrent access causes corruption. The business is willing to accept a downtime when an incident occurs, but the application must be available 24/7 to support their business operations. You need to design the architecture of this application on Google Cloud. What should you do?",
      "options": {
        "A": "Use a managed instance group with instances in multiple zones, use Cloud Filestore, and use an HTTP load balancer in front of the instances.",
        "B": "Use a managed instance group with instances in multiple zones, use Cloud Filestore, and use a network load balancer in front of the instances.",
        "C": "Use an unmanaged instance group with an active and standby instance in different zones, use a regional persistent disk, and use an HTTP load balancer in front of the instances.",
        "D": "Use an unmanaged instance group with an active and standby instance in different zones, use a regional persistent disk, and use a network load balancer in front of the instances."
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "No clear GCP pattern found. Selected A randomly to avoid bias. Manual review needed.",
      "metadata": {
        "topic": "General",
        "page": 4,
        "source": "Questions_15.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q7_105",
      "number": "105",
      "description": "Your company has an application running on multiple Compute Engine instances. You need to ensure that the application can communicate with an on-premises service that requires high throughput via internal IPs, while minimizing latency. What should you do?",
      "options": {
        "A": "Use OpenVPN to Configure a VPN tunnel between the on-premises environment and Google Cloud.",
        "B": "Configure a direct peering connection between the on-premises environment and Google Cloud.",
        "C": "Use Cloud VPN to Configure a VPN tunnel between the on-premises environment and Google Cloud.",
        "D": "Configure a Cloud Dedicated Interconnect connection between the on-premises environment and Google Cloud."
      },
      "introductory_info": "",
      "answers": {
        "community": "C",
        "highly_voted": "",
        "most_recent": "",
        "claude": "C"
      },
      "claude_reasoning": "No clear GCP pattern found. Selected C randomly to avoid bias. Manual review needed.",
      "metadata": {
        "topic": "General",
        "page": 7,
        "source": "Questions_15.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q12_107",
      "number": "107",
      "description": "You are monitoring Google Kubernetes Engine (GKE) clusters in a Cloud Monitoring workspace. As a Site Reliability Engineer (SRE), you need to triage incidents quickly. What should you do?",
      "options": {
        "A": "Navigate the predefined dashboards in the Cloud Monitoring workspace, and then add metrics and create alert policies.",
        "B": "Navigate the predefined dashboards in the Cloud Monitoring workspace, create custom metrics, and install alerting software on a Compute Engine instance.",
        "C": "Write a shell script that gathers metrics from GKE nodes, publish these metrics to a Pub/Sub topic, export the data to BigQuery, and make a Data Studio dashboard.",
        "D": "Create a custom dashboard in the Cloud Monitoring workspace for each incident, and then add metrics and create alert policies."
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "GKE provides managed Kubernetes with best practices. A: navigate the predefined dashboards in the cloud monitoring workspace, and then add metrics and creat...",
      "metadata": {
        "topic": "General",
        "page": 12,
        "source": "Questions_15.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q14_108",
      "number": "108",
      "description": "You are implementing a single Cloud SQL MySQL second-generation database that contains business-critical transaction data. You want to ensure that the minimum amount of data is lost in case of catastrophic failure. Which two features should you implement? (Choose two.)",
      "options": {
        "A": "Sharding",
        "B": "Read replicas",
        "C": "Binary logging",
        "D": "Automated backups",
        "E": "Semisynchronous replication"
      },
      "introductory_info": "",
      "answers": {
        "community": "B",
        "highly_voted": "",
        "most_recent": "",
        "claude": "B"
      },
      "claude_reasoning": "Option B best matches question context: read replicas...",
      "metadata": {
        "topic": "General",
        "page": 14,
        "source": "Questions_15.pdf",
        "confidence": 0.7,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q1_110",
      "number": "110",
      "description": "Your company has announced that they will be outsourcing operations functions. You want to allow developers to easily stage new versions of a cloud-based application in the production environment and allow the outsourced operations team to autonomously promote staged versions to production. You want to minimize the operational overhead of the solution. Which Google Cloud product should you migrate to?",
      "options": {
        "A": "App Engine",
        "B": "GKE On-Prem",
        "C": "Compute Engine",
        "D": "Google Kubernetes Engine"
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "Selected A because it uses GCP services (app engine): app engine...",
      "metadata": {
        "topic": "General",
        "page": 1,
        "source": "Questions_16.pdf",
        "confidence": 0.7,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q3_111",
      "number": "111",
      "description": "Your company is running its application workloads on Compute Engine. The applications have been deployed in production, acceptance, and development environments. The production environment is business-critical and is used 24/7, while the acceptance and development environments are only critical during oOce hours. Your CFO has asked you to optimize these environments to achieve cost savings during idle times. What should you do?",
      "options": {
        "A": "Create a shell script that uses the gcloud command to change the machine type of the development and acceptance instances to a smaller machine type outside of oOce hours. Schedule the shell script on one of the production instances to automate the task.",
        "B": "Use Cloud Scheduler to trigger a Cloud Function that will stop the development and acceptance environments after oOce hours and start them just before oOce hours.",
        "C": "Deploy the development and acceptance applications on a managed instance group and enable autoscaling.",
        "D": "Use regular Compute Engine instances for the production environment, and use preemptible VMs for the acceptance and development environments."
      },
      "introductory_info": "",
      "answers": {
        "community": "D",
        "highly_voted": "",
        "most_recent": "",
        "claude": "D"
      },
      "claude_reasoning": "Selected D because it uses GCP services (compute engine): use regular compute engine instances for the production environment, and use preemptible vms for the acceptance and deve...",
      "metadata": {
        "topic": "General",
        "page": 3,
        "source": "Questions_16.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q8_113",
      "number": "113",
      "description": "Your organization has decided to restrict the use of external IP addresses on instances to only approved instances. You want to enforce this requirement across all of your Virtual Private Clouds (VPCs). What should you do?",
      "options": {
        "A": "Remove the default route on all VPCs. Move all approved instances into a new subnet that has a default route to an internet gateway.",
        "B": "Create a new VPC in custom mode. Create a new subnet for the approved instances, and set a default route to the internet gateway on this new subnet.",
        "C": "Implement a Cloud NAT solution to remove the need for external IP addresses entirely.",
        "D": "Set an Organization Policy with a constraint on constraints/compute.vmExternalIpAccess. List the approved instances in the allowedValues list."
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "GCP best practice suggests A: remove the default route on all vpcs. move all approved instances into a new subnet that has a defau...",
      "metadata": {
        "topic": "General",
        "page": 8,
        "source": "Questions_16.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q10_114",
      "number": "114",
      "description": "Your company uses the Firewall Insights feature in the Google Network Intelligence Center. You have several Krewall rules applied to Compute Engine instances. You need to evaluate the eOciency of the applied Krewall ruleset. When you bring up the Firewall Insights page in the Google Cloud Console, you notice that there are no log rows to display. What should you do to troubleshoot the issue?",
      "options": {
        "A": "Enable Virtual Private Cloud (VPC) ^ow logging.",
        "B": "Enable Firewall Rules Logging for the Krewall rules you want to monitor.",
        "C": "Verify that your user account is assigned the compute.networkAdmin Identity and Access Management (IAM) role.",
        "D": "Install the Google Cloud SDK, and verify that there are no Firewall logs in the command line output."
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "GCP best practice suggests A: enable virtual private cloud (vpc) ^ow logging....",
      "metadata": {
        "topic": "General",
        "page": 10,
        "source": "Questions_16.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q14_116",
      "number": "116",
      "description": "You have developed a non-critical update to your application that is running in a managed instance group, and have created a new instance template with the update that you want to release. To prevent any possible impact to the application, you don't want to update any running instances. You want any new instances that are created by the managed instance group to contain the new update. What should you do?",
      "options": {
        "A": "Start a new rolling restart operation.",
        "B": "Start a new rolling replace operation.",
        "C": "Start a new rolling update. Select the Proactive update mode.",
        "D": "Start a new rolling update. Select the Opportunistic update mode."
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "No clear GCP pattern found. Selected A randomly to avoid bias. Manual review needed.",
      "metadata": {
        "topic": "General",
        "page": 14,
        "source": "Questions_16.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q19_118",
      "number": "118",
      "description": "Your company has just acquired another company, and you have been asked to integrate their existing Google Cloud environment into your company's data center. Upon investigation, you discover that some of the RFC 1918 IP ranges being used in the new company's Virtual Private Cloud (VPC) overlap with your data center IP space. What should you do to enable connectivity and make sure that there are no routing con^icts when connectivity is established?",
      "options": {
        "A": "Create a Cloud VPN connection from the new VPC to the data center, create a Cloud Router, and apply new IP addresses so there is no overlapping IP space.",
        "B": "Create a Cloud VPN connection from the new VPC to the data center, and create a Cloud NAT instance to perform NAT on the overlapping IP space.",
        "C": "Create a Cloud VPN connection from the new VPC to the data center, create a Cloud Router, and apply a custom route advertisement to block the overlapping IP space.",
        "D": "Create a Cloud VPN connection from the new VPC to the data center, and apply a Krewall rule that blocks the overlapping IP space."
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "GCP best practice suggests A: create a cloud vpn connection from the new vpc to the data center, create a cloud router, and apply ...",
      "metadata": {
        "topic": "General",
        "page": 19,
        "source": "Questions_16.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q1_7",
      "number": "7",
      "description": "To reduce costs, the Director of Engineering has required all developers to move their development infrastructure resources from on-premises virtual machines (VMs) to Google Cloud Platform. These resources go through multiple start/stop events during the day and require state to persist. You have been asked to design the process of running a development environment in Google Cloud while providing cost visibility to the Knance department. Which two steps should you take? (Choose two.)",
      "options": {
        "A": "Use the - -no-auto-delete ^ag on all persistent disks and stop the VM",
        "B": "Use the - -auto-delete ^ag on all persistent disks and terminate the VM",
        "C": "Apply VM CPU utilization label and include it in the BigQuery billing export",
        "D": "Use Google BigQuery billing export and labels to associate cost to groups",
        "E": "Store all state into local SSD, snapshot the persistent disks, and terminate the VM",
        "F": "Store all state in Google Cloud Storage, snapshot the persistent disks, and terminate the VM"
      },
      "introductory_info": "",
      "answers": {
        "community": "C",
        "highly_voted": "",
        "most_recent": "",
        "claude": "C"
      },
      "claude_reasoning": "Selected C because it uses GCP services (bigquery): apply vm cpu utilization label and include it in the bigquery billing export...",
      "metadata": {
        "topic": "General",
        "page": 1,
        "source": "Questions_2.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q6_9",
      "number": "9",
      "description": "You set up an autoscaling instance group to serve web traffic for an upcoming launch. After conKguring the instance group as a backend service to an HTTP(S) load balancer, you notice that virtual machine (VM) instances are being terminated and re-launched every minute. The instances do not have a public IP address. You have veriKed the appropriate web response is coming from each instance using the curl command. You want to ensure the backend is Configured correctly. What should you do?",
      "options": {
        "A": "Ensure that a Krewall rules exists to allow source traffic on HTTP/HTTPS to reach the load balancer.",
        "B": "Assign a public IP to each instance and Configure a Krewall rule to allow the load balancer to reach the instance public IP.",
        "C": "Ensure that a Krewall rule exists to allow load balancer health checks to reach the instances in the instance group.",
        "D": "Create a tag on each instance with the name of the load balancer. Configure a Krewall rule with the name of the load balancer as the source and the instance tag as the destination."
      },
      "introductory_info": "",
      "answers": {
        "community": "C",
        "highly_voted": "",
        "most_recent": "",
        "claude": "C"
      },
      "claude_reasoning": "Option C best matches question context: ensure that a krewall rule exists to allow load balancer health checks to reach the instances in the instance group....",
      "metadata": {
        "topic": "General",
        "page": 6,
        "source": "Questions_2.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q8_10",
      "number": "10",
      "description": "You write a Python script to connect to Google BigQuery from a Google Compute Engine virtual machine. The script is printing errors that it cannot What should you do to Kx the script?",
      "options": {
        "A": "Install the latest BigQuery API client library for Python",
        "B": "Run your script on a new virtual machine with the BigQuery access scope enabled",
        "C": "Create a new service account with BigQuery access and execute your script with that user",
        "D": "Install the bq component for gcloud with the command gcloud components install bq."
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "BigQuery is optimal for large-scale data analytics. A: install the latest bigquery api client library for python...",
      "metadata": {
        "topic": "General",
        "page": 8,
        "source": "Questions_2.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q20_14",
      "number": "14",
      "description": "A production database virtual machine on Google Compute Engine has an ext4-formatted persistent disk for data Kles. The database is about to run out of storage space. How can you remediate the problem with the least amount of downtime?",
      "options": {
        "A": "In the Cloud Platform Console, increase the size of the persistent disk and use the resize2fs command in Linux.",
        "B": "Shut down the virtual machine, use the Cloud Platform Console to increase the persistent disk size, then restart the virtual machine",
        "C": "In the Cloud Platform Console, increase the size of the persistent disk and verify the new space is ready to use with the fdisk command in Linux"
      },
      "introductory_info": "",
      "answers": {
        "community": "C",
        "highly_voted": "",
        "most_recent": "",
        "claude": "C"
      },
      "claude_reasoning": "No clear GCP pattern found. Selected C randomly to avoid bias. Manual review needed.",
      "metadata": {
        "topic": "General",
        "page": 20,
        "source": "Questions_2.pdf",
        "confidence": 0.7000000000000001,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q5_16",
      "number": "16",
      "description": "You have been asked to select the storage system for the click-data of your company's large portfolio of websites. This data is streamed in from a custom website analytics package at a typical rate of 6,000 clicks per minute. With bursts of up to 8,500 clicks per second. It must have been stored for future analysis by your data science and user experience teams. Which storage infrastructure should you choose?",
      "options": {
        "A": "Google Cloud SQL",
        "B": "Google Cloud Bigtable",
        "C": "Google Cloud Storage",
        "D": "Google Cloud Datastore"
      },
      "introductory_info": "",
      "answers": {
        "community": "C",
        "highly_voted": "",
        "most_recent": "",
        "claude": "C"
      },
      "claude_reasoning": "Selected C because it uses GCP services (cloud storage): google cloud storage...",
      "metadata": {
        "topic": "General",
        "page": 5,
        "source": "Questions_3.pdf",
        "confidence": 0.7,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q7_17",
      "number": "17",
      "description": "You are creating a solution to remove backup Kles older than 90 days from your backup Cloud Storage bucket. You want to optimize ongoing Cloud Storage spend. What should you do?",
      "options": {
        "A": "Write a lifecycle management rule in XML and push it to the bucket with gsutil",
        "B": "Write a lifecycle management rule in JSON and push it to the bucket with gsutil",
        "C": "Schedule a cron script using gsutil ls ג€\"lr gs://backups/** to find and remove items older than 90 days",
        "D": "Schedule a cron script using gsutil ls ג€\"l gs://backups/** to find and remove items older than 90 days and schedule it with cron"
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "Cloud Storage offers lifecycle management and scalability. A: write a lifecycle management rule in xml and push it to the bucket with gsutil...",
      "metadata": {
        "topic": "General",
        "page": 7,
        "source": "Questions_3.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q12_19",
      "number": "19",
      "description": "The database administration team has asked you to help them improve the performance of their new database server running on Google Compute Engine. The database is for importing and normalizing their performance statistics and is built with MySQL running on Debian Linux. They have an n1-standard-8 virtual machine with 80 GB of SSD persistent disk. What should they change to get better performance from this system?",
      "options": {
        "A": "Increase the virtual machine's memory to 64 GB",
        "B": "Create a new virtual machine running PostgreSQL",
        "C": "Dynamically resize the SSD persistent disk to 500 GB",
        "D": "Migrate their performance metrics warehouse to BigQuery",
        "E": "Modify all of their batch jobs to use bulk inserts into the database"
      },
      "introductory_info": "",
      "answers": {
        "community": "D",
        "highly_voted": "",
        "most_recent": "",
        "claude": "D"
      },
      "claude_reasoning": "Selected D because it uses GCP services (bigquery): migrate their performance metrics warehouse to bigquery...",
      "metadata": {
        "topic": "General",
        "page": 12,
        "source": "Questions_3.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q16_21",
      "number": "21",
      "description": "Your company's user-feedback portal comprises a standard LAMP stack replicated across two zones. It is deployed in the us-central1 region and uses autoscaled managed instance groups on all layers, except the database. Currently, only a small group of select customers have access to the portal. The portal meets a 99,99% availability SLA under these conditions. However next quarter, your company will be making the portal available to all users, including unauthenticated users. You need to develop a resiliency testing strategy to ensure the system maintains the SLA once they introduce additional What should you do?",
      "options": {
        "A": "Capture existing users input, and replay captured user load until autoscale is triggered on all layers. At the same time, terminate all resources in one of the zones",
        "B": "Create synthetic random user input, replay synthetic load until autoscale logic is triggered on at least one layer, and introduce ג€chaosג€ to the system by terminating random resources on both zones",
        "C": "Expose the new system to a larger group of users, and increase group size each day until autoscale logic is triggered on all layers. At the same time, terminate random resources on both zones",
        "D": "Capture existing users input, and replay captured user load until resource utilization crosses 80%. Also, derive estimated number of users based on existing user's usage of the app, and deploy enough resources to handle 200% of expected load"
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "Addresses scalability requirements: Capture existing users input, and replay captured user load until autoscale is triggered on all layers. At the same time...",
      "metadata": {
        "topic": "General",
        "page": 16,
        "source": "Questions_3.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q2_23",
      "number": "23",
      "description": "Your solution is producing performance bugs in production that you did not see in staging and test environments. You want to adjust your test and deployment procedures to avoid this problem in the future. What should you do?",
      "options": {
        "A": "Deploy fewer changes to production",
        "B": "Deploy smaller changes to production",
        "C": "Increase the load on your test and staging environments",
        "D": "Deploy changes to a small subset of users before rolling out to production"
      },
      "introductory_info": "",
      "answers": {
        "community": "C",
        "highly_voted": "",
        "most_recent": "",
        "claude": "C"
      },
      "claude_reasoning": "No clear GCP pattern found. Selected C randomly to avoid bias. Manual review needed.",
      "metadata": {
        "topic": "General",
        "page": 2,
        "source": "Questions_4.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q5_24",
      "number": "24",
      "description": "A small number of API requests to your microservices-based application take a very long time. You know that each request to the API can traverse many services. You want to know which service takes the longest in those cases. What should you do?",
      "options": {
        "A": "Set timeouts on your application so that you can fail requests faster",
        "B": "Send custom metrics for each of your requests to Stackdriver Monitoring",
        "C": "Use Stackdriver Monitoring to look for insights that show when your API latencies are high"
      },
      "introductory_info": "",
      "answers": {
        "community": "C",
        "highly_voted": "",
        "most_recent": "",
        "claude": "C"
      },
      "claude_reasoning": "No clear GCP pattern found. Selected C randomly to avoid bias. Manual review needed.",
      "metadata": {
        "topic": "General",
        "page": 5,
        "source": "Questions_4.pdf",
        "confidence": 0.7000000000000001,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q10_26",
      "number": "26",
      "description": "Your organization requires that metrics from all applications be retained for 5 years for future analysis in possible legal proceedings. Which approach should you use?",
      "options": {
        "A": "Grant the security team access to the logs in each Project",
        "B": "Configure Stackdriver Monitoring for all Projects, and export to BigQuery",
        "C": "Configure Stackdriver Monitoring for all Projects with the default retention policies",
        "D": "Configure Stackdriver Monitoring for all Projects, and export to Google Cloud Storage"
      },
      "introductory_info": "",
      "answers": {
        "community": "B",
        "highly_voted": "",
        "most_recent": "",
        "claude": "B"
      },
      "claude_reasoning": "Selected B because it uses GCP services (bigquery): configure stackdriver monitoring for all projects, and export to bigquery...",
      "metadata": {
        "topic": "General",
        "page": 10,
        "source": "Questions_4.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q16_28",
      "number": "28",
      "description": "Auditors visit your teams every 12 months and ask to review all the Google Cloud Identity and Access Management (Cloud IAM) policy changes in the previous 12 months. You want to streamline and expedite the analysis and audit process. What should you do?",
      "options": {
        "A": "Create custom Google Stackdriver alerts and send them to the auditor",
        "B": "Enable Logging export to Google BigQuery and use ACLs and views to scope the data shared with the auditor",
        "C": "Use cloud functions to transfer log entries to Google Cloud SQL and use ACLs and views to limit an auditor's view",
        "D": "Enable Google Cloud Storage (GCS) log export to audit logs into a GCS bucket and delegate access to the bucket"
      },
      "introductory_info": "",
      "answers": {
        "community": "C",
        "highly_voted": "",
        "most_recent": "",
        "claude": "C"
      },
      "claude_reasoning": "Selected C because it uses GCP services (cloud sql, cloud functions): use cloud functions to transfer log entries to google cloud sql and use acls and views to limit an auditor's view...",
      "metadata": {
        "topic": "General",
        "page": 16,
        "source": "Questions_4.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q19_29",
      "number": "29",
      "description": "You are designing a large distributed application with 30 microservices. Each of your distributed microservices needs to connect to a database back-end. You want to store the credentials securely. Where should you store the credentials?",
      "options": {
        "A": "In the source code",
        "B": "In an environment variable",
        "C": "In a secret management system"
      },
      "introductory_info": "",
      "answers": {
        "community": "B",
        "highly_voted": "",
        "most_recent": "",
        "claude": "B"
      },
      "claude_reasoning": "No clear GCP pattern found. Selected B randomly to avoid bias. Manual review needed.",
      "metadata": {
        "topic": "General",
        "page": 19,
        "source": "Questions_4.pdf",
        "confidence": 0.7000000000000001,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q5_31",
      "number": "31",
      "description": "A development manager is building a new application. He asks you to review his requirements and identify what cloud technologies he can use to meet them. The application must: 1. Be based on open-source technology for cloud portability 2. Dynamically scale compute capacity based on demand 3. Support continuous software delivery 4. Run multiple segregated copies of the same application stack 5. Deploy application bundles using dynamic templates 6. Route network traffic to speciKc services based on URL Which combination of technologies will meet all of his requirements?",
      "options": {
        "A": "Google Kubernetes Engine, Jenkins, and Helm",
        "B": "Google Kubernetes Engine and Cloud Load Balancing",
        "C": "Google Kubernetes Engine and Cloud Deployment Manager",
        "D": "Google Kubernetes Engine, Jenkins, and Cloud Load Balancing"
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "Selected A because it uses GCP services (kubernetes): google kubernetes engine, jenkins, and helm...",
      "metadata": {
        "topic": "General",
        "page": 5,
        "source": "Questions_5.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q11_33",
      "number": "33",
      "description": "Your organization has a 3-tier web application deployed in the same network on Google Cloud Platform. Each tier (web, API, and database) scales independently of the others. Network traffic should ^ow through the web to the API tier and then on to the database tier. traffic should not ^ow between the web and the database tier. How should you Configure the network?",
      "options": {
        "A": "Add each tier to a different subnetwork",
        "B": "Set up software based Krewalls on individual VMs",
        "C": "Add tags to each tier and set up routes to allow the desired traffic ^ow",
        "D": "Add tags to each tier and set up Krewall rules to allow the desired traffic ^ow"
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "GCP best practice suggests A: add each tier to a different subnetwork...",
      "metadata": {
        "topic": "General",
        "page": 11,
        "source": "Questions_5.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q19_36",
      "number": "36",
      "description": "You created a pipeline that can deploy your source code changes to your infrastructure in instance groups for self-healing. One of the changes negatively affects your key performance indicator. You are not sure how to Kx it, and investigation could take up to a week. What should you do?",
      "options": {
        "A": "Log in to a server, and iterate on the fox locally",
        "B": "Revert the source code change, and rerun the deployment pipeline",
        "C": "Log into the servers with the bad code change, and swap in the previous code",
        "D": "Change the instance group template to the previous one, and delete all instances"
      },
      "introductory_info": "",
      "answers": {
        "community": "D",
        "highly_voted": "",
        "most_recent": "",
        "claude": "D"
      },
      "claude_reasoning": "No clear GCP pattern found. Selected D randomly to avoid bias. Manual review needed.",
      "metadata": {
        "topic": "General",
        "page": 19,
        "source": "Questions_5.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q2_37",
      "number": "37",
      "description": "Your organization wants to control IAM policies for different departments independently, but centrally. Which approach should you take?",
      "options": {
        "A": "Multiple Organizations with multiple Folders",
        "B": "Multiple Organizations, one for each department",
        "C": "A single Organization with Folders for each department",
        "D": "A single Organization with multiple projects, each with a central owner"
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "No clear GCP pattern found. Selected A randomly to avoid bias. Manual review needed.",
      "metadata": {
        "topic": "General",
        "page": 2,
        "source": "Questions_6.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q7_39",
      "number": "39",
      "description": "You are designing a mobile chat application. You want to ensure people cannot spoof chat messages, by providing a message were sent by a speciKc user. What should you do?",
      "options": {
        "A": "Tag messages client side with the originating user identiKer and the destination user.",
        "B": "Encrypt the message client side using block-based encryption with a shared key.",
        "C": "Use public key infrastructure (PKI) to encrypt the message client side using the originating user's private key.",
        "D": "Use a trusted certiKcate authority to enable SSL connectivity between the client application and the server."
      },
      "introductory_info": "",
      "answers": {
        "community": "B",
        "highly_voted": "",
        "most_recent": "",
        "claude": "B"
      },
      "claude_reasoning": "No clear GCP pattern found. Selected B randomly to avoid bias. Manual review needed.",
      "metadata": {
        "topic": "General",
        "page": 7,
        "source": "Questions_6.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q16_42",
      "number": "42",
      "description": "You are using Cloud Shell and need to install a custom utility for use in a few weeks. Where can you store the Kle so it is in the default execution path and persists across sessions?",
      "options": {
        "B": "Cloud Storage",
        "C": "/google/scripts",
        "D": "/usr/local/bin"
      },
      "introductory_info": "",
      "answers": {
        "community": "B",
        "highly_voted": "",
        "most_recent": "",
        "claude": "B"
      },
      "claude_reasoning": "Selected B because it uses GCP services (cloud storage): cloud storage...",
      "metadata": {
        "topic": "General",
        "page": 16,
        "source": "Questions_6.pdf",
        "confidence": 0.6000000000000001,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q19_43",
      "number": "43",
      "description": "You want to create a private connection between your instances on Compute Engine and your on-premises data center. You require a connection of at least 20 Gbps. You want to follow Google-recommended practices. How should you set up the connection?",
      "options": {
        "A": "Create a VPC and connect it to your on-premises data center using Dedicated Interconnect.",
        "B": "Create a VPC and connect it to your on-premises data center using a single Cloud VPN.",
        "C": "Create a Cloud Content Delivery Network (Cloud CDN) and connect it to your on-premises data center using Dedicated Interconnect.",
        "D": "Create a Cloud Content Delivery Network (Cloud CDN) and connect it to your on-premises datacenter using a single Cloud VPN."
      },
      "introductory_info": "",
      "answers": {
        "community": "D",
        "highly_voted": "",
        "most_recent": "",
        "claude": "D"
      },
      "claude_reasoning": "No clear GCP pattern found. Selected D randomly to avoid bias. Manual review needed.",
      "metadata": {
        "topic": "General",
        "page": 19,
        "source": "Questions_6.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q1_44",
      "number": "44",
      "description": "You are analyzing and deKning business processes to support your startup's trial usage of GCP, and you don't yet know what consumer demand for your product will be. Your manager requires you to minimize GCP service costs and adhere to Google best practices. What should you do?",
      "options": {
        "A": "Utilize free tier and sustained use discounts. Provision a staff position for service cost management.",
        "B": "Utilize free tier and sustained use discounts. Provide training to the team about service cost management.",
        "C": "Utilize free tier and committed use discounts. Provision a staff position for service cost management.",
        "D": "Utilize free tier and committed use discounts. Provide training to the team about service cost management."
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "Option A best matches question context: utilize free tier and sustained use discounts. provision a staff position for service cost management....",
      "metadata": {
        "topic": "General",
        "page": 1,
        "source": "Questions_7.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q4_45",
      "number": "45",
      "description": "You are building a continuous deployment pipeline for a project stored in a Git source repository and want to ensure that code changes can be veriKed before deploying to production. What should you do?",
      "options": {
        "A": "Use Spinnaker to deploy builds to production using the red/black deployment strategy so that changes can easily be rolled back.",
        "B": "Use Spinnaker to deploy builds to production and run tests on production deployments.",
        "C": "Use Jenkins to build the staging branches and the master branch. Build and deploy changes to production for 10% of users before doing a complete rollout.",
        "D": "Use Jenkins to monitor tags in the repository. Deploy staging tags to a staging environment for testing. After testing, tag the repository for production and deploy that to the production environment."
      },
      "introductory_info": "",
      "answers": {
        "community": "C",
        "highly_voted": "",
        "most_recent": "",
        "claude": "C"
      },
      "claude_reasoning": "No clear GCP pattern found. Selected C randomly to avoid bias. Manual review needed.",
      "metadata": {
        "topic": "General",
        "page": 4,
        "source": "Questions_7.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q7_46",
      "number": "46",
      "description": "You have an outage in your Compute Engine managed instance group: all instances keep restarting after 5 seconds. You have a health check Configured, but autoscaling is disabled. Your colleague, who is a Linux expert, offered to look into the issue. You need to make sure that he can access the VMs. What should you do?",
      "options": {
        "A": "Grant your colleague the IAM role of project Viewer",
        "B": "Perform a rolling restart on the instance group",
        "C": "Disable the health check for the instance group. Add his SSH key to the project-wide SSH Keys",
        "D": "Disable autoscaling for the instance group. Add his SSH key to the project-wide SSH Keys"
      },
      "introductory_info": "",
      "answers": {
        "community": "D",
        "highly_voted": "",
        "most_recent": "",
        "claude": "D"
      },
      "claude_reasoning": "GCP best practice suggests D: disable autoscaling for the instance group. add his ssh key to the project-wide ssh keys...",
      "metadata": {
        "topic": "General",
        "page": 7,
        "source": "Questions_7.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q10_47",
      "number": "47",
      "description": "Your company is migrating its on-premises data center into the cloud. As part of the migration, you want to integrate Google Kubernetes Engine (GKE) for workload orchestration. Parts of your architecture must also be PCI DSS-compliant. Which of the following is most accurate?",
      "options": {
        "A": "App Engine is the only compute platform on GCP that is certiKed for PCI DSS hosting.",
        "B": "GKE cannot be used under PCI DSS because it is considered shared hosting.",
        "C": "GKE and GCP provide the tools you need to build a PCI DSS-compliant environment.",
        "D": "All Google Cloud services are usable because Google Cloud Platform is certiKed PCI-compliant."
      },
      "introductory_info": "",
      "answers": {
        "community": "B",
        "highly_voted": "",
        "most_recent": "",
        "claude": "B"
      },
      "claude_reasoning": "Option B best matches question context: gke cannot be used under pci dss because it is considered shared hosting....",
      "metadata": {
        "topic": "General",
        "page": 10,
        "source": "Questions_7.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q12_48",
      "number": "48",
      "description": "Your company has multiple on-premises systems that serve as sources for reporting. The data has not been maintained well and has become degraded over time. You want to use Google-recommended practices to detect anomalies in your company data. What should you do?",
      "options": {
        "A": "Upload your Kles into Cloud Storage. Use Cloud Datalab to explore and clean your data.",
        "B": "Upload your Kles into Cloud Storage. Use Cloud Dataprep to explore and clean your data.",
        "C": "Connect Cloud Datalab to your on-premises systems. Use Cloud Datalab to explore and clean your data.",
        "D": "Connect Cloud Dataprep to your on-premises systems. Use Cloud Dataprep to explore and clean your data."
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "Selected A because it uses GCP services (cloud storage): upload your kles into cloud storage. use cloud datalab to explore and clean your data....",
      "metadata": {
        "topic": "General",
        "page": 12,
        "source": "Questions_7.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q15_49",
      "number": "49",
      "description": "Google Cloud Platform resources are managed hierarchically using organization, folders, and projects. When Cloud Identity and Access Management (IAM) policies exist at these different levels, what is the effective policy at a particular node of the hierarchy?",
      "options": {
        "A": "The effective policy is determined only by the policy set at the node",
        "B": "The effective policy is the policy set at the node and restricted by the policies of its ancestors",
        "C": "The effective policy is the union of the policy set at the node and policies inherited from its ancestors",
        "D": "The effective policy is the intersection of the policy set at the node and policies inherited from its ancestors"
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "No clear GCP pattern found. Selected A randomly to avoid bias. Manual review needed.",
      "metadata": {
        "topic": "General",
        "page": 15,
        "source": "Questions_7.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q17_50",
      "number": "50",
      "description": "You are migrating your on-premises solution to Google Cloud in several phases. You will use Cloud VPN to maintain a connection between your on-premises systems and Google Cloud until the migration is completed. You want to make sure all your on-premise systems remain reachable during this period. How should you organize your networking in Google Cloud?",
      "options": {
        "A": "Use the same IP range on Google Cloud as you use on-premises",
        "B": "Use the same IP range on Google Cloud as you use on-premises for your primary IP range and use a secondary range that does not overlap with the range you use on-premises",
        "C": "Use an IP range on Google Cloud that does not overlap with the range you use on-premises",
        "D": "Use an IP range on Google Cloud that does not overlap with the range you use on-premises for your primary IP range and use a secondary range with the same IP range as you use on-premises"
      },
      "introductory_info": "",
      "answers": {
        "community": "C",
        "highly_voted": "",
        "most_recent": "",
        "claude": "C"
      },
      "claude_reasoning": "No clear GCP pattern found. Selected C randomly to avoid bias. Manual review needed.",
      "metadata": {
        "topic": "General",
        "page": 17,
        "source": "Questions_7.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q1_51",
      "number": "51",
      "description": "You have found an error in your App Engine application caused by missing Cloud Datastore indexes. You have created a YAML Kle with the required indexes and want to deploy these new indexes to Cloud Datastore. What should you do?",
      "options": {
        "A": "Point gcloud datastore create-indexes to your conKguration Kle",
        "B": "Upload the conKguration Kle to App Engine's default Cloud Storage bucket, and have App Engine detect the new indexes",
        "C": "In the GCP Console, use Datastore Admin to delete the current indexes and upload the new conKguration Kle",
        "D": "Create an HTTP request to the built-in python module to send the index conKguration Kle to your application"
      },
      "introductory_info": "",
      "answers": {
        "community": "B",
        "highly_voted": "",
        "most_recent": "",
        "claude": "B"
      },
      "claude_reasoning": "Selected B because it uses GCP services (cloud storage, app engine): upload the conkguration kle to app engine's default cloud storage bucket, and have app engine detect the new indexes...",
      "metadata": {
        "topic": "General",
        "page": 1,
        "source": "Questions_8.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q3_52",
      "number": "52",
      "description": "You have an application that will run on Compute Engine. You need to design an architecture that takes into account a disaster recovery plan that requires your application to fail over to another region in case of a regional outage. What should you do?",
      "options": {
        "A": "Deploy the application on two Compute Engine instances in the same project but in a different region. Use the Krst instance to serve traffic, and use the HTTP load balancing service to fail over to the standby instance in case of a disaster.",
        "B": "Deploy the application on a Compute Engine instance. Use the instance to serve traffic, and use the HTTP load balancing service to fail over to an instance on your premises in case of a disaster.",
        "C": "Deploy the application on two Compute Engine instance groups, each in the same project but in a different region. Use the Krst instance group to serve traffic, and use the HTTP load balancing service to fail over to the standby instance group in case of a disaster.",
        "D": "Deploy the application on two Compute Engine instance groups, each in a separate project and a different region. Use the Krst instance group to serve traffic, and use the HTTP load balancing service to fail over to the standby instance group in case of a disaster."
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "Selected A because it uses GCP services (compute engine): deploy the application on two compute engine instances in the same project but in a different region. use the krst insta...",
      "metadata": {
        "topic": "General",
        "page": 3,
        "source": "Questions_8.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q6_53",
      "number": "53",
      "description": "You are deploying an application on App Engine that needs to integrate with an on-premises database. For security purposes, your on-premises database must not be accessible through the public internet. What should you do?",
      "options": {
        "A": "Deploy your application on App Engine standard environment and use App Engine Krewall rules to limit access to the open on-premises database.",
        "B": "Deploy your application on App Engine standard environment and use Cloud VPN to limit access to the on-premises database.",
        "C": "Deploy your application on App Engine ^exible environment and use App Engine Krewall rules to limit access to the on-premises database.",
        "D": "Deploy your application on App Engine ^exible environment and use Cloud VPN to limit access to the on-premises database."
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "Selected A because it uses GCP services (app engine): deploy your application on app engine standard environment and use app engine krewall rules to limit access to the open ...",
      "metadata": {
        "topic": "General",
        "page": 6,
        "source": "Questions_8.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q16_56",
      "number": "56",
      "description": "You have an application deployed on Google Kubernetes Engine using a Deployment named echo-deployment. The deployment is exposed using a Service called echo-service. You need to perform an update to the application with minimal downtime to the application. What should you do?",
      "options": {
        "A": "Use kubectl set image deployment/echo-deployment <new-image>",
        "B": "Use the rolling update functionality of the Instance Group behind the Kubernetes cluster",
        "C": "Update the deployment yaml Kle with the new container image. Use kubectl delete deployment/echo-deployment and kubectl create ג€\"f <yaml-Kle>",
        "D": "Update the service yaml Kle which the new container image. Use kubectl delete service/echo-service and kubectl create ג€\"f <yaml-Kle>"
      },
      "introductory_info": "",
      "answers": {
        "community": "B",
        "highly_voted": "",
        "most_recent": "",
        "claude": "B"
      },
      "claude_reasoning": "Selected B because it uses GCP services (kubernetes): use the rolling update functionality of the instance group behind the kubernetes cluster...",
      "metadata": {
        "topic": "General",
        "page": 16,
        "source": "Questions_8.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q19_57",
      "number": "57",
      "description": "Your company is using BigQuery as its enterprise data warehouse. Data is distributed over several Google Cloud projects. All queries on BigQuery need to be billed on a single project. You want to make sure that no query costs are incurred on the projects that contain the data. Users should be able to query the datasets, but not edit them. How should you Configure users' access roles?",
      "options": {
        "A": "Add all users to a group. Grant the group the role of BigQuery user on the billing project and BigQuery dataViewer on the projects that contain the data.",
        "B": "Add all users to a group. Grant the group the roles of BigQuery dataViewer on the billing project and BigQuery user on the projects that contain the data.",
        "C": "Add all users to a group. Grant the group the roles of BigQuery jobUser on the billing project and BigQuery dataViewer on the projects that contain the data.",
        "D": "Add all users to a group. Grant the group the roles of BigQuery dataViewer on the billing project and BigQuery jobUser on the projects that contain the data."
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "BigQuery is optimal for large-scale data analytics. A: add all users to a group. grant the group the role of bigquery user on the billing project and bigqu...",
      "metadata": {
        "topic": "General",
        "page": 19,
        "source": "Questions_8.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q3_58",
      "number": "58",
      "description": "You have developed an application using Cloud ML Engine that recognizes famous paintings from uploaded images. You want to test the application and allow speciKc people to upload images for the next 24 hours. Not all users have a Google Account. How should you have users upload images?",
      "options": {
        "A": "Have users upload the images to Cloud Storage. Protect the bucket with a password that expires after 24 hours.",
        "B": "Have users upload the images to Cloud Storage using a signed URL that expires after 24 hours.",
        "C": "Create an App Engine web application where users can upload images. Configure App Engine to disable the application after 24 hours. Authenticate users via Cloud Identity.",
        "D": "Create an App Engine web application where users can upload images for the next 24 hours. Authenticate users via Cloud Identity."
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "Selected A because it uses GCP services (cloud storage): have users upload the images to cloud storage. protect the bucket with a password that expires after 24 hours....",
      "metadata": {
        "topic": "General",
        "page": 3,
        "source": "Questions_9.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q11_61",
      "number": "61",
      "description": "The development team has provided you with a Kubernetes Deployment Kle. You have no infrastructure yet and need to deploy the application. What should you do?",
      "options": {
        "A": "Use gcloud to create a Kubernetes cluster. Use Deployment Manager to create the deployment.",
        "B": "Use gcloud to create a Kubernetes cluster. Use kubectl to create the deployment.",
        "C": "Use kubectl to create a Kubernetes cluster. Use Deployment Manager to create the deployment.",
        "D": "Use kubectl to create a Kubernetes cluster. Use kubectl to create the deployment."
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "Selected A because it uses GCP services (kubernetes): use gcloud to create a kubernetes cluster. use deployment manager to create the deployment....",
      "metadata": {
        "topic": "General",
        "page": 11,
        "source": "Questions_9.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q13_62",
      "number": "62",
      "description": "You need to evaluate your team readiness for a new GCP project. You must perform the evaluation and create a skills gap plan which incorporates the business goal of cost optimization. Your team has deployed two GCP projects successfully to date. What should you do?",
      "options": {
        "A": "Allocate budget for team training. Set a deadline for the new GCP project.",
        "B": "Allocate budget for team training. Create a roadmap for your team to achieve Google Cloud certiKcation based on job role.",
        "C": "Allocate budget to hire skilled external consultants. Set a deadline for the new GCP project.",
        "D": "Allocate budget to hire skilled external consultants. Create a roadmap for your team to achieve Google Cloud certiKcation based on job role."
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "Addresses cost requirements: Allocate budget for team training. Set a deadline for the new GCP project....",
      "metadata": {
        "topic": "General",
        "page": 13,
        "source": "Questions_9.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q15_63",
      "number": "63",
      "description": "You are designing an application for use only during business hours. For the minimum viable product release, you'd like to use a managed product that automatically `scales to zero` so you don't incur costs when there is no activity. Which primary compute resource should you choose?",
      "options": {
        "A": "Cloud Functions",
        "B": "Compute Engine",
        "C": "Google Kubernetes Engine",
        "D": "AppEngine ^exible environment"
      },
      "introductory_info": "",
      "answers": {
        "community": "A",
        "highly_voted": "",
        "most_recent": "",
        "claude": "A"
      },
      "claude_reasoning": "Selected A because it uses GCP services (cloud functions): cloud functions...",
      "metadata": {
        "topic": "General",
        "page": 15,
        "source": "Questions_9.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "Q18_64",
      "number": "64",
      "description": "You are creating an App Engine application that uses Cloud Datastore as its persistence layer. You need to retrieve several root entities for which you have the identiKers. You want to minimize the overhead in operations performed by Cloud Datastore. What should you do?",
      "options": {
        "A": "Create the Key object for each Entity and run a batch get operation",
        "B": "Create the Key object for each Entity and run multiple get operations, one operation for each entity",
        "C": "Use the identiKers to create a query Klter and run a batch query operation",
        "D": "Use the identiKers to create a query Klter and run multiple query operations, one operation for each entity"
      },
      "introductory_info": "",
      "answers": {
        "community": "D",
        "highly_voted": "",
        "most_recent": "",
        "claude": "D"
      },
      "claude_reasoning": "No clear GCP pattern found. Selected D randomly to avoid bias. Manual review needed.",
      "metadata": {
        "topic": "General",
        "page": 18,
        "source": "Questions_9.pdf",
        "confidence": 0.7999999999999999,
        "has_claude_answer": true
      },
      "editable": true
    },
    {
      "id": "case_study_dress4win_1",
      "number": "1",
      "description": "For this question, refer to the Dress4Win case study. Dress4Win is expected to grow to 10 times its size in 1 year with a corresponding growth in data and traOc that mirrors the existing patterns of usage. The CIO has set the target of migrating production infrastructure to the cloud within the next 6 months. How will you conKgure the solution to scale for this growth without making major application changes and still maximize the ROI?",
      "options": {
        "A": "Migrate the web application layer to App Engine, and MySQL to Cloud Datastore, and NAS to Cloud Storage. Deploy RabbitMQ, and deploy Hadoop servers using Deployment Manager.",
        "B": "Migrate RabbitMQ to Cloud Pub/Sub, Hadoop to BigQuery, and NAS to Compute Engine with Persistent Disk storage. Deploy Tomcat, and deploy Nginx using Deployment Manager.",
        "C": "Implement managed instance groups for Tomcat and Nginx. Migrate MySQL to Cloud SQL, RabbitMQ to Cloud Pub/Sub, Hadoop to Cloud Dataproc, and NAS to Compute Engine with Persistent Disk storage.",
        "D": "Implement managed instance groups for the Tomcat and Nginx. Migrate MySQL to Cloud SQL, RabbitMQ to Cloud Pub/Sub, Hadoop to Cloud Dataproc, and NAS to Cloud Storage. MeasService"
      },
      "community_answer": "D",
      "highly_voted_answer": "e",
      "most_recent_answer": "e",
      "all_community_comments": "Highly Voted 4 years, 8 months ago Why do we need to put NAS data on persistant disk and not on GCS ? I would go with D! upvoted 43 times techalik 3 years, 6 months ago 1. Use Cloud Marketplace to provision Tomcat and Nginx on Google Compute Engine. 2. Replace MySQL with Cloud SQL for MySQL. 3. Use the Deployment Manager to provision Jenkins on Google Compute Engine. is the right answer. As explained above, you would use Cloud SQL to replace MySQL. For the other requirements, i.e. Nginx/Tomcat and Jenkins, you can deploy these through Cloud Deployment Manager by using custom images. Ref: https://cloud.google.com/compute/docs/images Using the same custom images every time ensures that your environments are \"reliable and reproducible\" and you achieve \"rapid provisioning\". D upvoted 11 times nitinz 3 years, 3 months ago ans is D upvoted 4 times tartar 3 years, 10 months ago D is ok upvoted 11 times Jphix 3 years, 5 months ago Agreed. Looking to maximize ROI as well according to the question, and even the most expensive cloud storage is still going to be half the price of cheapest Persistent Disk storage, and that's without even including your compute costs. D all the way. upvoted 3 times https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 782 / 803 --- PAGE 3 --- Profess\"onal Cloud Arch\"tect Exam - Free Actual Q&As, Page 1 | ExamTop\"cs 19.12.2024 13:49 KouShikyou Highly Voted 4 years, 8 months ago I prefer D. Original NAS is for image, log, backup. GCS fits it perfectly. upvoted 21 times exampanic 4 years, 5 months ago I agree that GCS fits perfectly for storing images, log, backup. However, the question asks to avoid major application changes. GCS is not NAS, meaning it does not provide SMB or NFS shares. Therefore moving the NAS files to Google Cloud Storage would require a major application change in the way they access these files. I believe the correct answer would be C. upvoted 10 times poseidon24 2 years, 10 months ago It can, check on Cloud Storage FUSE. Buckets can be mounted as file systems. upvoted 4 times mesodan Most Recent 3 months, 2 weeks ago Selected Answer: D Use case suitability: Cloud Storage: Ideally suited for storing large, unstructured data like images, videos, and backups, which is likely the case for Dress4Win's NAS data. Persistent Disk: More appropriate for frequently accessed data that requires block-level access, such as databases or operating systems for virtual machines. upvoted 1 times kampatra 4 months, 1 week ago Selected Answer: D Correct Ans: A NAS `\" image storage, logs, backups : for storing images, logs and backups Cloud Storage is best practice and cost effective also. upvoted 1 times kampatra 4 months, 1 week ago Wrongly typed A, it must be D upvoted 1 times mbacelar 6 months, 1 week ago Selected Answer: D Should be D upvoted 1 times MahAli 6 months, 1 week ago Selected Answer: C Voting c NAS could have been replaced with file store to minimize any change, moving to GCS is not that easy change in overall architecture upvoted 1 times Jannchie 6 months, 1 week ago Selected Answer: C C, because we can run some script on NAS. It can act like a normal server. But GCS cannot. upvoted 2 times techtitan 6 months, 2 weeks ago Selected Answer: C without making major application changes and still maximize the ROI --> compute engine with persistent disk. without knowing access patterns, GCS may not be an easy change. upvoted 1 times thamaster 1 year, 5 months ago Selected Answer: D you don't need NAS to store archive and Image disk upvoted 1 times https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 783 / 803 --- PAGE 4 --- Profess\"onal Cloud Arch\"tect Exam - Free Actual Q&As, Page 1 | ExamTop\"cs 19.12.2024 13:49 amxexam 2 years ago Selected Answer: D D is the correct chand equivalent mapping upvoted 1 times [Removed] 2 years, 3 months ago D is OK https://cloud.google.com/architecture/filers-on-compute-engine?hl=en#managed_file_storage_solutions upvoted 2 times MF2C 2 years, 5 months ago SAN -> persistent disk, NAS -> Cloud Storage upvoted 2 times edilramos 2 years, 5 months ago Managed Instances With Tomcat and Nginx would bring the minimum necessary tweaking to the new environment. Migrating from MySql to Cloud SQL does not require any syntax changes. Moving from Rabbit MQ to Pub/Sub is relatively straightforward and has very complete documentation. DataProc has Libraries and tools to ensure Apache Hadoop interoperability. Without many changes in the environment, mainly keeping the original architecture, Datastorage will keep the presentation characteristics of a shared area, mapped to the instances. upvoted 2 times phantomsg 2 years, 6 months ago Selected Answer: C The answer should be C. 'A' and 'B' are ruled out as they introduce significant architecture changes. or irrelevant. 'D' is fine except proposes to replace NAS with Cloud Storage. This will introduce major architectural changes. Instead, if the choice was to move 'NAS' to 'Cloud Filestore' then it would have made sense. Answer 'C' is the closest with the least amount of architectural changes involved in migration. upvoted 3 times joe2211 2 years, 6 months ago Selected Answer: D vote D upvoted 3 times kopper2019 2 years, 11 months ago hey guys new Qs posted as of July 12th, 2021, All 21 new Qs in Question #152 upvoted 1 times anku15 2 years, 9 months ago I dont see the questions now. Did you remove it? upvoted 1 times victory108 2 years, 11 months ago D. Implement managed instance groups for the Tomcat and Nginx. Migrate MySQL to Cloud SQL, RabbitMQ to Cloud Pub/Sub, Hadoop to Cloud Dataproc, and NAS to Cloud Storage. upvoted 1 times Question #2 Topic 12 https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 784 / 803 --- PAGE 5 --- Profess\"onal Cloud Arch\"tect Exam - Free Actual Q&As, Page 1 | ExamTop\"cs 19.12.2024 13:49 Introductory Info Company Overview - Dress4Win is a web-based company that helps their users organize and manage their personal wardrobe using a web app and mobile application. The company also cultivates an active social network that connects their users with designers and retailers. They monetize their services through advertising, e-commerce, referrals, and a freemium app model. The application has grown from a few servers in the founder's garage to several hundred servers and appliances in a colocated data center. However, the capacity of their infrastructure is now insuOcient for the application's rapid growth. Because of this growth and the company's desire to innovate faster, Dress4Win is committing to a full migration to a public cloud. Solution Concept - For the Krst phase of their migration to the cloud, Dress4Win is moving their development and test environments. They are also building a disaster recovery site, because their current infrastructure is at a single location. They are not sure which components of their architecture they can migrate as is and which components they need to change before migrating them. Existing Technical Environment - The Dress4Win application is served out of a single data center location. All servers run Ubuntu LTS v16.04. Databases: MySQL. 1 server for user data, inventory, static data: - MySQL 5.8 - 8 core CPUs - 128 GB of RAM - 2x 5 TB HDD (RAID 1) Redis 3 server cluster for metadata, social graph, caching. Each server is: - Redis 3.2 - 4 core CPUs - 32GB of RAM Compute: 40 Web Application servers providing micro-services based APIs and static content. `\" - Tomcat Java - - Nginx - 4 core CPUs - 32 GB of RAM 20 Apache Hadoop/Spark servers: - Data analysis - Real-time trending calculations - 8 core CPUs - 128 GB of RAM - 4x 5 TB HDD (RAID 1) 3 RabbitMQ servers for messaging, social notiKcations, and events: - 8 core CPUs - 32GB of RAM Miscellaneous servers: - Jenkins, monitoring, bastion hosts, security scanners - 8 core CPUs - 32GB of RAM Storage appliances: iSCSI for VM hosts https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 785 / 803 --- PAGE 6 --- Profess\"onal Cloud Arch\"tect Exam - Free Actual Q&As, Page 1 | ExamTop\"cs 19.12.2024 13:49 Fiber channel SAN `\" MySQL databases - 1 PB total storage; 400 TB available NAS `\" image storage, logs, backups - 100 TB total storage; 35 TB available Business Requirements - Build a reliable and reproducible environment with scaled parity of production. Improve security by deKning and adhering to a set of security and Identity and Access Management (IAM) best practices for cloud. Improve business agility and speed of innovation through rapid provisioning of new resources. Analyze and optimize architecture for performance in the cloud. Technical Requirements - Easily create non-production environments in the cloud. Implement an automation framework for provisioning resources in cloud. Implement a continuous deployment process for deploying applications to the on-premises datacenter or cloud. Support failover of the production environment to cloud during an emergency. Encrypt data on the wire and at rest. Support multiple private connections between the production data center and cloud environment. Executive Statement - Our investors are concerned about our ability to scale and contain costs with our current infrastructure. They are also concerned that a competitor could use a public cloud platform to offset their up-front investment and free them to focus on developing better features. Our traOc patterns are highest in the mornings and weekend evenings; during other times, 80% of our capacity is sitting idle. Our capital expenditure is now exceeding our quarterly projections. Migrating to the cloud will likely cause an initial increase in spending, but we expect to fully transition before our next hardware refresh cycle. Our total cost of ownership (TCO) analysis over the next 5 years for a public cloud strategy achieves a cost reduction between 30% and 50% over our current model. Question For this question, refer to the Dress4Win case study. Considering the given business requirements, how would you automate the deployment of web and transactional data layers? A. Deploy Nginx and Tomcat using Cloud Deployment Manager to Compute Engine. Deploy a Cloud SQL server to replace MySQL. Deploy Jenkins using Cloud Deployment Manager. B. Deploy Nginx and Tomcat using Cloud Launcher. Deploy a MySQL server using Cloud Launcher. Deploy Jenkins to Compute Engine using Cloud Deployment Manager scripts. C. Migrate Nginx and Tomcat to App Engine. Deploy a Cloud Datastore server to replace the MySQL server in a high-availability conKguration. Deploy Jenkins to Compute Engine using Cloud Launcher. D. Migrate Nginx and Tomcat to App Engine. Deploy a MySQL server using Cloud Launcher. Deploy Jenkins to Compute Engine using Cloud Launcher. jcmoranp Highly Voted 4 years, 1 month ago It's A, \"Cloud Datastore server\" doesn't exist. A fits OK. upvoted 26 times nitinz 2 years, 9 months ago A is the answer upvoted 2 times https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 786 / 803 --- PAGE 7 --- Profess\"onal Cloud Arch\"tect Exam - Free Actual Q&As, Page 1 | ExamTop\"cs 19.12.2024 13:49 cetanx 3 years, 4 months ago Also, GAE uses Jetty for http and servlet engine. Therefore Tomcat cannot be run on GAE (unless on flexible env.) - this rules out \"C and D\" upvoted 2 times tartar 3 years, 4 months ago A is ok upvoted 5 times Jphix 2 years, 11 months ago agreed, A. For those saying C, the question is about \"automating the deployment\" in line with the business requirements. Going from MySQL to datastore might be a good idea long term, but it won't make automating the deployment to the cloud any easier or smoother. Automate the deployment to Cloud SQL because it's a natural fit, and once that's working, re-assess the requirements to decide if it's worth the hefty lift of shifting from MySQL to a NoSQL Document DB. upvoted 1 times Eroc Highly Voted 4 years, 1 month ago The requriements also specify: \"Easily create non-production environment in the cloud. Implement an automation framework for provisioning resources in cloud. Implement a continuous deployment process for deploying applications to the on-premises datacenter or cloud.\" So A is better. upvoted 11 times SSQX 3 years, 8 months ago You can only deploy Jenkins with Cloud Launcher, not with Deployment manager upvoted 2 times Ayzen 3 years, 7 months ago Jenkins is just an app that should be run on a VM. You definitely can use Deployment Manager to set up a VM with needed image. upvoted 3 times theBestStudent Most Recent 1 week, 2 days ago Selected Answer: D For me is D: - Deploy NGINX and and Tomcat to App Engine, so both can scale up and down automatically - Deploy MySQL server using Cloud Launcer (nowadays called Marketplace) - Deploy Jenkins to Compute Engine using Cloud Launcher (nowadays called MarketPlace): Here literally they are choosing an instance (a compute instance to do so through MarketPlace) https://cloud.google.com/architecture/using-jenkins-for-distributed-builds-on-compute-engine. Answer A can not be. it talks about SQL Server, why to bring that? Plus the way they want ton tackle Jenkins installation makes no sense if you already have MarketPlace. Also I'm ok that compute instances for NGINX and Tomcat could fit, BUT it doesn't talk about MIG or not MIG. It is not ensuring right declaration to have MIG and scale them up down through it will be in place. Answer is D. upvoted 1 times tuan072090 3 months, 1 week ago Selected Answer: A A is the most sense answer upvoted 1 times joe2211 2 years ago Selected Answer: A vote A upvoted 1 times victory108 2 years, 5 months ago A. Deploy Nginx and Tomcat using Cloud Deployment Manager to Compute Engine. Deploy a Cloud SQL server to replace MySQL. Deploy Jenkins using Cloud Deployment Manager. upvoted 2 times MamthaSJ 2 years, 5 months ago Answer is A upvoted 2 times https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 787 / 803 --- PAGE 8 --- Profess\"onal Cloud Arch\"tect Exam - Free Actual Q&As, Page 1 | ExamTop\"cs 19.12.2024 13:49 gosi 2 years, 7 months ago D. With produciton parity, you cant replace MySQL with 128 GB of memory with Cloud SQL as there is no such image available. I have checked it. MySQL has to go on GCE with PD I would go for either go for B or D. D is better because it is scalable better than B as B has no details if it is going to use MIG or just fleet of tomcat servers for web apps. upvoted 1 times Ausias18 2 years, 8 months ago Answer is A upvoted 1 times vruizm 2 years, 9 months ago I think B is a valid response, please check: https://cloud.google.com/blog/products/it-ops/google-cloud-launcher-simplifies-running-third-party-apps-in-the-cloud and https://medium.com/@PeetDenny/automated-provisioning-of-jenkins-on-google-cloud-c297b2e0be2 upvoted 2 times bnlcnd 2 years, 10 months ago the question and the answers are so confusing. what is \"Cloud Launcher\"? Never heard of it. Only A does not mention that launcher thingy. I can only choose A. upvoted 2 times Wira 2 years, 9 months ago its an old question - its cloud marketplace now given size of mysql and type of data, the only valid choice is C for me upvoted 2 times pawel_ski 2 years, 9 months ago It's the previous name of GCP Marketplace. upvoted 1 times ybe_gcp_cert 2 years, 11 months ago A or B; B doesn't tell which automation tool is used to deploy Cloud SQL. Cloud launcher generates Cloud Deployment Manager scripts. I would go with B upvoted 1 times ybe_gcp_cert 2 years, 11 months ago Sorry A doesn't tell which tool is used to deploy Cloud SQL. I would go with B. upvoted 1 times Mndwsk 3 years ago B. Only option that automates the deployment of all the tools mentioned. Cloud Launcher creates a Deployment in Deployment Manager. upvoted 1 times SKSKSK 3 years, 1 month ago After reading the question more and kind of linking back to question one, i think it's asking how to \"automate the deployment\" of web and transactional data layers\". In that case, I think focus on deployment automation of existing technology might be a better than mapping new cloud technology in this case? so, A might be a better fit? upvoted 1 times homer_simpson 3 years, 1 month ago the answer is A because datastore is nosql db and in business requirements it is clarly sais that improve bussiness agility and speed innovation through rapid provisoning of new ressources upvoted 1 times brati_sankar 3 years, 2 months ago I believe this is D. Here is my logic. In D we are using a MySQL from the Marketplace. Presently, on-prem the amount of data is 600 TB (1 PB SAN for MySQL of which 400 TB is free) . This would not go in Cloud SQL which has a limit of 30 TB. Hence, we must go for MySQL on compute using Launcher/Marketplace. upvoted 4 times https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 788 / 803 --- PAGE 9 --- Profess\"onal Cloud Arch\"tect Exam - Free Actual Q&As, Page 1 | ExamTop\"cs 19.12.2024 13:49 roastc 3 years, 2 months ago I don't think there is any automation mentioned while using Cloud Launcher. So the answer should be A upvoted 2 times Question #3 Topic 12 Introductory Info Company Overview - Dress4Win is a web-based company that helps their users organize and manage their personal wardrobe using a web app and mobile application. The company also cultivates an active social network that connects their users with designers and retailers. They monetize their services through advertising, e-commerce, referrals, and a freemium app model. The application has grown from a few servers in the founder's garage to several hundred servers and appliances in a colocated data center. However, the capacity of their infrastructure is now insuOcient for the application's rapid growth. Because of this growth and the company's desire to innovate faster, Dress4Win is committing to a full migration to a public cloud. Solution Concept - For the Krst phase of their migration to the cloud, Dress4Win is moving their development and test environments. They are also building a disaster recovery site, because their current infrastructure is at a single location. They are not sure which components of their architecture they can migrate as is and which components they need to change before migrating them. Existing Technical Environment - The Dress4Win application is served out of a single data center location. All servers run Ubuntu LTS v16.04. Databases: MySQL. 1 server for user data, inventory, static data: - MySQL 5.8 - 8 core CPUs - 128 GB of RAM - 2x 5 TB HDD (RAID 1) Redis 3 server cluster for metadata, social graph, caching. Each server is: - Redis 3.2 - 4 core CPUs - 32GB of RAM Compute: 40 Web Application servers providing micro-services based APIs and static content. `\" - Tomcat Java - - Nginx - 4 core CPUs - 32 GB of RAM 20 Apache Hadoop/Spark servers: - Data analysis https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 789 / 803 --- PAGE 10 --- Profess\"onal Cloud Arch\"tect Exam - Free Actual Q&As, Page 1 | ExamTop\"cs 19.12.2024 13:49 - Real-time trending calculations - 8 core CPUs - 128 GB of RAM - 4x 5 TB HDD (RAID 1) 3 RabbitMQ servers for messaging, social notiKcations, and events: - 8 core CPUs - 32GB of RAM Miscellaneous servers: - Jenkins, monitoring, bastion hosts, security scanners - 8 core CPUs - 32GB of RAM Storage appliances: iSCSI for VM hosts Fiber channel SAN `\" MySQL databases - 1 PB total storage; 400 TB available NAS `\" image storage, logs, backups - 100 TB total storage; 35 TB available Business Requirements - Build a reliable and reproducible environment with scaled parity of production. Improve security by deKning and adhering to a set of security and Identity and Access Management (IAM) best practices for cloud. Improve business agility and speed of innovation through rapid provisioning of new resources. Analyze and optimize architecture for performance in the cloud. Technical Requirements - Easily create non-production environments in the cloud. Implement an automation framework for provisioning resources in cloud. Implement a continuous deployment process for deploying applications to the on-premises datacenter or cloud. Support failover of the production environment to cloud during an emergency. Encrypt data on the wire and at rest. Support multiple private connections between the production data center and cloud environment. Executive Statement - Our investors are concerned about our ability to scale and contain costs with our current infrastructure. They are also concerned that a competitor could use a public cloud platform to offset their up-front investment and free them to focus on developing better features. Our traOc patterns are highest in the mornings and weekend evenings; during other times, 80% of our capacity is sitting idle. Our capital expenditure is now exceeding our quarterly projections. Migrating to the cloud will likely cause an initial increase in spending, but we expect to fully transition before our next hardware refresh cycle. Our total cost of ownership (TCO) analysis over the next 5 years for a public cloud strategy achieves a cost reduction between 30% and 50% over our current model. Question For this question, refer to the Dress4Win case study. Which of the compute services should be migrated as-is and would still be an optimized architecture for performance in the cloud? A. Web applications deployed using App Engine standard environment B. RabbitMQ deployed using an unmanaged instance group C. Hadoop/Spark deployed using Cloud Dataproc Regional in High Availability mode D. Jenkins, monitoring, bastion hosts, security scanners services deployed on custom machine types Hemant_C 3 years ago https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 790 / 803 --- PAGE 11 --- Profess\"onal Cloud Arch\"tect Exam - Free Actual Q&As, Page 1 | ExamTop\"cs 19.12.2024 13:49 Hemant_C Highly Voted 3 years ago Question is about compute services to be migrated as \"\"is and would still be an optimized architecture for performance - Apache Hadoop/Spark servers underline is compute and Hadoop/Spark deployed using Cloud Dataproc seems to be the correct answer.. Hence C seems correct answer to me upvoted 29 times SAMBIT 1 year, 3 months ago They are not sure which components of their architecture they can migrate as is and which components they need to change before migrating them. upvoted 1 times jcmoranp Highly Voted 3 years, 7 months ago It's D. You cannot migrate to APP Engine \"as-is\" upvoted 19 times tartar 2 years, 10 months ago C is ok upvoted 11 times army234 2 years, 2 months ago C is correct upvoted 7 times akhilesh_pundir Most Recent 4 months, 2 weeks ago Read the previous questions ... they are going to use Managed instance groups with Tomcat &nginx installed on that so app engine is not in picture. Hadoop workloads goes to dataproc as it is. upvoted 1 times OrangeTiger 1 year, 5 months ago Selected Answer: C I agree with C. 'as-is' upvoted 4 times ABO_Doma 1 year, 6 months ago Google Cloud includes Dataproc, which is a managed Hadoop and Spark environment. You can use Dataproc to run most of your existing jobs with minimal alteration, so you don't need to move away from all of the Hadoop tools you already know. upvoted 2 times ABO_Doma 1 year, 6 months ago Selected Answer: C Answer is C upvoted 2 times joe2211 1 year, 6 months ago Selected Answer: C vote C upvoted 2 times victory108 1 year, 11 months ago C. Hadoop/Spark deployed using Cloud Dataproc Regional in High Availability mode upvoted 6 times MamthaSJ 1 year, 11 months ago Answer is C upvoted 4 times Ausias18 2 years, 2 months ago Answer is C upvoted 2 times https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 791 / 803 --- PAGE 12 --- Profess\"onal Cloud Arch\"tect Exam - Free Actual Q&As, Page 1 | ExamTop\"cs 19.12.2024 13:49 hkmsn 2 years, 3 months ago A. Web applications deployed using App Engine standard environment - there are multiple web apps, seems project limit of 1 - and not clear on the implications of Standard Env, with Nginx (there seems to be discussions) -- no not clear on this. B. RabbitMQ - is always replaced by Pub/Sub - So No. C. Hadoop/Spark - This is a well know Use Case D. Jenkins, Etc, these duplicate GCP products so it can't be the answer. My bet is C upvoted 2 times ahmedemad3 2 years, 4 months ago ans: C compute services should be migrated as is and would still be an optimized architecture for performance in the cloud? upvoted 1 times bnlcnd 2 years, 4 months ago It's C. hardoop == dataproc. pretty much a cloud version. D is \"Jenkins, monitoring, bastion hosts, security scanners\". How can you make them as-is to run in cloud? Monitoring? on-prem to cloud no change? security scanner? no change? upvoted 3 times BobBui 2 years, 4 months ago I choose C upvoted 1 times okixavi 2 years, 6 months ago C is the correct answer. The question says: \"...as is\" upvoted 1 times practicioner 2 years, 7 months ago C and D make sense. However, \"would still be an optimized architecture\". In this case, I chose C because we can move our services as is and we can get significant benefits from GCP upvoted 1 times gcparchitect007 2 years, 7 months ago C is correct answer. upvoted 1 times Question #4 Topic 12 Introductory Info Company Overview - Dress4Win is a web-based company that helps their users organize and manage their personal wardrobe using a web app and mobile application. The company also cultivates an active social network that connects their users with designers and retailers. They monetize their services through advertising, e-commerce, referrals, and a freemium app model. The application has grown from a few servers in the founder's garage to several hundred servers and appliances in a colocated data center. However, the capacity of their infrastructure is now insuOcient for the application's rapid growth. Because of this growth and the company's desire to innovate faster, Dress4Win is committing to a full migration to a public cloud. Solution Concept - For the Krst phase of their migration to the cloud, Dress4Win is moving their development and test environments. They are also building a disaster recovery site, because their current infrastructure is at a single location. They are not sure which components of their architecture they can migrate as is and which components they need to change before migrating them. Existing Technical Environment - The Dress4Win application is served out of a single data center location. All servers run Ubuntu LTS v16.04. Databases: MySQL. 1 server for user data, inventory, static data: - MySQL 5.8 https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 792 / 803 --- PAGE 13 --- Profess\"onal Cloud Arch\"tect Exam - Free Actual Q&As, Page 1 | ExamTop\"cs 19.12.2024 13:49 - 8 core CPUs - 128 GB of RAM - 2x 5 TB HDD (RAID 1) Redis 3 server cluster for metadata, social graph, caching. Each server is: - Redis 3.2 - 4 core CPUs - 32GB of RAM Compute: 40 Web Application servers providing micro-services based APIs and static content. `\" - Tomcat Java - - Nginx - 4 core CPUs - 32 GB of RAM 20 Apache Hadoop/Spark servers: - Data analysis - Real-time trending calculations - 8 core CPUs - 128 GB of RAM - 4x 5 TB HDD (RAID 1) 3 RabbitMQ servers for messaging, social notiKcations, and events: - 8 core CPUs - 32GB of RAM Miscellaneous servers: - Jenkins, monitoring, bastion hosts, security scanners - 8 core CPUs - 32GB of RAM Storage appliances: iSCSI for VM hosts Fiber channel SAN `\" MySQL databases - 1 PB total storage; 400 TB available NAS `\" image storage, logs, backups - 100 TB total storage; 35 TB available Business Requirements - Build a reliable and reproducible environment with scaled parity of production. Improve security by deKning and adhering to a set of security and Identity and Access Management (IAM) best practices for cloud. Improve business agility and speed of innovation through rapid provisioning of new resources. Analyze and optimize architecture for performance in the cloud. Technical Requirements - Easily create non-production environments in the cloud. Implement an automation framework for provisioning resources in cloud. Implement a continuous deployment process for deploying applications to the on-premises datacenter or cloud. Support failover of the production environment to cloud during an emergency. Encrypt data on the wire and at rest. Support multiple private connections between the production data center and cloud environment. https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 793 / 803 --- PAGE 14 --- Profess\"onal Cloud Arch\"tect Exam - Free Actual Q&As, Page 1 | ExamTop\"cs 19.12.2024 13:49 Executive Statement - Our investors are concerned about our ability to scale and contain costs with our current infrastructure. They are also concerned that a competitor could use a public cloud platform to offset their up-front investment and free them to focus on developing better features. Our traOc patterns are highest in the mornings and weekend evenings; during other times, 80% of our capacity is sitting idle. Our capital expenditure is now exceeding our quarterly projections. Migrating to the cloud will likely cause an initial increase in spending, but we expect to fully transition before our next hardware refresh cycle. Our total cost of ownership (TCO) analysis over the next 5 years for a public cloud strategy achieves a cost reduction between 30% and 50% over our current model. Question For this question, refer to the Dress4Win case study. To be legally compliant during an audit, Dress4Win must be able to give insights in all administrative actions that modify the conKguration or metadata of resources on Google Cloud. What should you do? A. Use Stackdriver Trace to create a Trace list analysis. B. Use Stackdriver Monitoring to create a dashboard on the project's activity. C. Enable Cloud Identity-Aware Proxy in all projects, and add the group of Administrators as a member. D. Use the Activity page in the GCP Console and Stackdriver Logging to provide the required insight. MeasService Highly Voted 2 years, 2 months ago D is the correct answer ! https://cloud.google.com/logging/docs/audit/ upvoted 49 times nitinz 9 months, 2 weeks ago ans is D upvoted 3 times mikey007 1 year, 6 months ago Agree,... upvoted 3 times newbie2020 1 year, 11 months ago Agree, Answer is D upvoted 4 times Eroc 2 years, 1 month ago I agree upvoted 3 times joe2211 Most Recent 3 weeks ago Selected Answer: D vote D upvoted 2 times Shahariargcppca 1 month, 3 weeks ago answer is d upvoted 1 times victory108 5 months ago D. Use the Activity page in the GCP Console and Stackdriver Logging to provide the required insight. upvoted 1 times MamthaSJ 5 months, 1 week ago Answer is D.. upvoted 3 times https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 794 / 803 --- PAGE 15 --- Profess\"onal Cloud Arch\"tect Exam - Free Actual Q&As, Page 1 | ExamTop\"cs 19.12.2024 13:49 Ausias18 8 months, 3 weeks ago Answer is D upvoted 1 times lynx256 8 months, 3 weeks ago IMO - D is ok upvoted 2 times pihuanshu 10 months, 2 weeks ago D should be upvoted 2 times bnlcnd 10 months, 2 weeks ago D for sure upvoted 2 times Chulbul_Pandey 1 year ago D is the choice upvoted 1 times gcparchitect007 1 year, 1 month ago D is the right answer. upvoted 1 times homer_simpson 1 year, 1 month ago the answer is D Admin Activity audit logs Admin Activity audit logs contain log entries for API calls or other administrative actions that modify the configuration or metadata of resources. For example, these logs record when users create VM instances or change Identity and Access Management permissions. To view these logs, you must have the IAM role Logging/Logs Viewer or Project/Viewer. upvoted 1 times Kabiliravi 1 year, 3 months ago D is correct upvoted 1 times wiqi 1 year, 3 months ago D is correct. upvoted 1 times mbiy 1 year, 4 months ago D is the correct option upvoted 1 times ry9280087 1 year, 4 months ago Seriously GCP must have written these answers as poison pills. upvoted 3 times mlantonis 1 year, 5 months ago Yeah D is the correct upvoted 2 times Question #5 Topic 12 Introductory Info Company Overview - Dress4Win is a web-based company that helps their users organize and manage their personal wardrobe using a web app and mobile application. The company also cultivates an active social network that connects their users with designers and retailers. They monetize their services through advertising, e-commerce, referrals, and a freemium app model. The application has grown from a few servers in the founder's garage to several https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 795 / 803 --- PAGE 16 --- Profess\"onal Cloud Arch\"tect Exam - Free Actual Q&As, Page 1 | ExamTop\"cs 19.12.2024 13:49 hundred servers and appliances in a colocated data center. However, the capacity of their infrastructure is now insuOcient for the application's rapid growth. Because of this growth and the company's desire to innovate faster, Dress4Win is committing to a full migration to a public cloud. Solution Concept - For the Krst phase of their migration to the cloud, Dress4Win is moving their development and test environments. They are also building a disaster recovery site, because their current infrastructure is at a single location. They are not sure which components of their architecture they can migrate as is and which components they need to change before migrating them. Existing Technical Environment - The Dress4Win application is served out of a single data center location. All servers run Ubuntu LTS v16.04. Databases: MySQL. 1 server for user data, inventory, static data: - MySQL 5.8 - 8 core CPUs - 128 GB of RAM - 2x 5 TB HDD (RAID 1) Redis 3 server cluster for metadata, social graph, caching. Each server is: - Redis 3.2 - 4 core CPUs - 32GB of RAM Compute: 40 Web Application servers providing micro-services based APIs and static content. `\" - Tomcat Java - - Nginx - 4 core CPUs - 32 GB of RAM 20 Apache Hadoop/Spark servers: - Data analysis - Real-time trending calculations - 8 core CPUs - 128 GB of RAM - 4x 5 TB HDD (RAID 1) 3 RabbitMQ servers for messaging, social notiKcations, and events: - 8 core CPUs - 32GB of RAM Miscellaneous servers: - Jenkins, monitoring, bastion hosts, security scanners - 8 core CPUs - 32GB of RAM Storage appliances: iSCSI for VM hosts Fiber channel SAN `\" MySQL databases - 1 PB total storage; 400 TB available NAS `\" image storage, logs, backups - 100 TB total storage; 35 TB available Business Requirements - https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 796 / 803 --- PAGE 17 --- Profess\"onal Cloud Arch\"tect Exam - Free Actual Q&As, Page 1 | ExamTop\"cs 19.12.2024 13:49 Build a reliable and reproducible environment with scaled parity of production. Improve security by deKning and adhering to a set of security and Identity and Access Management (IAM) best practices for cloud. Improve business agility and speed of innovation through rapid provisioning of new resources. Analyze and optimize architecture for performance in the cloud. Technical Requirements - Easily create non-production environments in the cloud. Implement an automation framework for provisioning resources in cloud. Implement a continuous deployment process for deploying applications to the on-premises datacenter or cloud. Support failover of the production environment to cloud during an emergency. Encrypt data on the wire and at rest. Support multiple private connections between the production data center and cloud environment. Executive Statement - Our investors are concerned about our ability to scale and contain costs with our current infrastructure. They are also concerned that a competitor could use a public cloud platform to offset their up-front investment and free them to focus on developing better features. Our traOc patterns are highest in the mornings and weekend evenings; during other times, 80% of our capacity is sitting idle. Our capital expenditure is now exceeding our quarterly projections. Migrating to the cloud will likely cause an initial increase in spending, but we expect to fully transition before our next hardware refresh cycle. Our total cost of ownership (TCO) analysis over the next 5 years for a public cloud strategy achieves a cost reduction between 30% and 50% over our current model. Question For this question, refer to the Dress4Win case study. You are responsible for the security of data stored in Cloud Storage for your company, Dress4Win. You have already created a set of Google Groups and assigned the appropriate users to those groups. You should use Google best practices and implement the simplest design to meet the requirements. Considering Dress4Win's business and technical requirements, what should you do? A. Assign custom IAM roles to the Google Groups you created in order to enforce security requirements. Encrypt data with a customer- supplied encryption key when storing Kles in Cloud Storage. B. Assign custom IAM roles to the Google Groups you created in order to enforce security requirements. Enable default storage encryption before storing Kles in Cloud Storage. C. Assign predeKned IAM roles to the Google Groups you created in order to enforce security requirements. Utilize Google's default encryption at rest when storing Kles in Cloud Storage. D. Assign predeKned IAM roles to the Google Groups you created in order to enforce security requirements. Ensure that the default Cloud KMS key is set before storing Kles in Cloud Storage. JoeShmoe Highly Voted 5 years, 1 month ago C is the simplest upvoted 34 times https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 797 / 803 --- PAGE 18 --- Profess\"onal Cloud Arch\"tect Exam - Free Actual Q&As, Page 1 | ExamTop\"cs 19.12.2024 13:49 AWS56 4 years, 11 months ago I am a bit confused \"You should use Google best practices and implement the simplest design to meet the requirements.\" ---> Simplest -- agree with D, but for googles best practice I will go with A upvoted 3 times AWS56 4 years, 11 months ago Ignore my comment, Agree C is the simple -- https://cloud.google.com/compute/docs/disks/customer-supplied-encryption upvoted 4 times tartar 4 years, 4 months ago C is ok upvoted 5 times rockstar9622 4 years, 11 months ago c is correct - going by simplest design whereas google manages the encrytion though by default and thats sufficient upvoted 2 times nitinz 3 years, 9 months ago ans is C upvoted 3 times kimharsh 2 years, 8 months ago how come it's C , and for best practice we need to use Custom Roles upvoted 1 times newbie2020 Highly Voted 4 years, 11 months ago There 2 requirements 1) best practices = least privilege = custom role 2) simplest = default encryption as : If you use customer-supplied encryption keys or client-side encryption, you must securely manage your keys and ensure that they are not lost. If you lose your keys, you are no longer able to read your data, and you continue to be charged for storage of your objects until you delete them. upvoted 12 times Dannyygcp 4 years, 9 months ago What about option B..default encryption[which is simple to manage] + Custom role[which is secure compared to predefined and not difficult to create] upvoted 3 times sivass 4 years, 7 months ago I agrre. I will go with B. upvoted 5 times GCP_Azure 4 years, 7 months ago It has to be B upvoted 4 times Rafaa 4 years, 6 months ago there is no option to 'enable default encyption' as such! It is provided by default if you dont do anything. upvoted 2 times Vika 3 years, 8 months ago Check out this link - https://cloud.google.com/iam/docs/using-iam-securely Basic roles include thousands of permissions across all Google Cloud services. In production environments, do not grant basic roles unless there is no alternative. Instead, grant the most limited predefined roles or custom roles that meet your needs. upvoted 1 times tlopsm Most Recent 6 months, 1 week ago Selected Answer: C C is answer upvoted 1 times https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 798 / 803 --- PAGE 19 --- Profess\"onal Cloud Arch\"tect Exam - Free Actual Q&As, Page 1 | ExamTop\"cs 19.12.2024 13:49 Ahmed_Safwat 1 year, 1 month ago Selected Answer: D Encrypt Cloud Storage data with Cloud KMS upvoted 1 times SAMBIT 2 years, 9 months ago B custom IAM & out of box encryption upvoted 1 times joe2211 3 years ago Selected Answer: C vote C upvoted 2 times kopper2019 3 years, 5 months ago hey guys new Qs posted as of July 12th, 2021, All 21 new Qs in Question #152 upvoted 1 times kopper2019 3 years, 5 months ago hey guys new Qs posted as of July 12th, 2021, All 21 new Qs in Question #152 upvoted 1 times victory108 3 years, 5 months ago C. Assign predefined IAM roles to the Google Groups you created in order to enforce security requirements. Utilize Googleג€™s default encryption at rest when storing files in Cloud Storage. upvoted 2 times MamthaSJ 3 years, 5 months ago Answer is B upvoted 1 times wilwong 3 years, 5 months ago C is correct upvoted 1 times Pb55 3 years, 7 months ago C. Best practice is predefined not custom. Only use custom when predefined to broard. upvoted 1 times ansh0692 3 years, 8 months ago From \"Google's best practices and simplest design\" Answer should be C upvoted 1 times Skeeter 3 years, 8 months ago Cloud storage encryption is enabled by default. Why would you need to enable it as stated in B? Answer is A, use CSEK and specify a .boto file during upload with gsutil, simple! upvoted 2 times Ausias18 3 years, 8 months ago it says simple, what you say is not as easy as possible... default encryption is easier upvoted 1 times Ausias18 3 years, 8 months ago Answer is B upvoted 1 times lynx256 3 years, 8 months ago IMO - C is ok. Simplest --> predefined roles + default encryption Question #6 Topic 12 upvoted 2 times Rightsaidfred 3 years, 10 months ago Introductory Info C is the 'Google' answer here :) upvoted 1 times https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 799 / 803 --- PAGE 20 --- Profess\"onal Cloud Arch\"tect Exam - Free Actual Q&As, Page 1 | ExamTop\"cs 19.12.2024 13:49 Company Overview - Dress4Win is a web-based company that helps their users organize and manage their personal wardrobe using a web app and mobile application. The company also cultivates an active social network that connects their users with designers and retailers. They monetize their services through advertising, e-commerce, referrals, and a freemium app model. The application has grown from a few servers in the founder's garage to several hundred servers and appliances in a colocated data center. However, the capacity of their infrastructure is now insuOcient for the application's rapid growth. Because of this growth and the company's desire to innovate faster, Dress4Win is committing to a full migration to a public cloud. Solution Concept - For the Krst phase of their migration to the cloud, Dress4Win is moving their development and test environments. They are also building a disaster recovery site, because their current infrastructure is at a single location. They are not sure which components of their architecture they can migrate as is and which components they need to change before migrating them. Existing Technical Environment - The Dress4Win application is served out of a single data center location. All servers run Ubuntu LTS v16.04. Databases: MySQL. 1 server for user data, inventory, static data: - MySQL 5.8 - 8 core CPUs - 128 GB of RAM - 2x 5 TB HDD (RAID 1) Redis 3 server cluster for metadata, social graph, caching. Each server is: - Redis 3.2 - 4 core CPUs - 32GB of RAM Compute: 40 Web Application servers providing micro-services based APIs and static content. `\" - Tomcat Java - - Nginx - 4 core CPUs - 32 GB of RAM 20 Apache Hadoop/Spark servers: - Data analysis - Real-time trending calculations - 8 core CPUs - 128 GB of RAM - 4x 5 TB HDD (RAID 1) 3 RabbitMQ servers for messaging, social notiKcations, and events: - 8 core CPUs - 32GB of RAM Miscellaneous servers: - Jenkins, monitoring, bastion hosts, security scanners - 8 core CPUs - 32GB of RAM Storage appliances: iSCSI for VM hosts Fiber channel SAN `\" MySQL databases - 1 PB total storage; 400 TB available https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 800 / 803",
      "page_number": 1,
      "source_file": "Questions_40.pdf",
      "case_study_info": "Company Overview - Dress4Win is a web-based company that helps their users organize and manage their personal wardrobe using a web app and mobile application. The company also cultivates an active social network that connects their users with designers and retailers. They monetize their services through advertising, e-commerce, referrals, and a freemium app model. The application has grown from a few servers in the founder's garage to several hundred servers and appliances in a colocated data center. However, the capacity of their infrastructure is now insuOcient for the application's rapid growth. Because of this growth and the company's desire to innovate faster, Dress4Win is committing to a full migration to a public cloud. Solution Concept - For the Krst phase of their migration to the cloud, Dress4Win is moving their development and test environments. They are also building a disaster recovery site, because their current infrastructure is at a single location. They are not sure which components of their architecture they can migrate as is and which components they need to change before migrating them. Existing Technical Environment - The Dress4Win application is served out of a single data center location. All servers run Ubuntu LTS v16.04. Databases: MySQL. 1 server for user data, inventory, static data: - MySQL 5.8 - 8 core CPUs - 128 GB of RAM - 2x 5 TB HDD (RAID 1) Redis 3 server cluster for metadata, social graph, caching. Each server is: - Redis 3.2 - 4 core CPUs - 32GB of RAM Compute: 40 Web Application servers providing micro-services based APIs and static content. `\" - Tomcat Java - - Nginx - 4 core CPUs - 32 GB of RAM 20 Apache Hadoop/Spark servers: - Data analysis - Real-time trending calculations - 8 core CPUs - 128 GB of RAM - 4x 5 TB HDD (RAID 1) 3 RabbitMQ servers for messaging, social notiKcations, and events: - 8 core CPUs - 32GB of RAM Miscellaneous servers: - Jenkins, monitoring, bastion hosts, security scanners - 8 core CPUs - 32GB of RAM St",
      "confidence_score": 0.85,
      "claude_answer": "",
      "claude_reasoning": "",
      "topic": "Case Study",
      "latest_date": "3 days ago"
    },
    {
      "id": "case_study_dress4win_1",
      "number": "1",
      "description": "For this question, refer to the Dress4Win case study. You want to ensure that your on-premises architecture meets business requirements before you migrate your solution. What change in the on-premises architecture should you make?",
      "options": {
        "A": "Replace RabbitMQ with Google Pub/Sub.",
        "B": "Downgrade MySQL to v5.7, which is supported by Cloud SQL for MySQL.",
        "C": "Resize compute resources to match predeKned Compute Engine machine types.",
        "D": "Containerize the micro-services and host them in Google Kubernetes Engine. chiar"
      },
      "community_answer": "B",
      "highly_voted_answer": "e",
      "most_recent_answer": "e",
      "all_community_comments": "Highly Voted 5 years, 1 month ago Be careful, because in the case study that you can find in google website MySQL version is 5.7 https://cloud.google.com/certification/guides/cloud-architect/casestudy-dress4win-rev2 upvoted 20 times jasim21 3 years, 8 months ago cloud SQL support MySQL 5.7 https://cloud.google.com/sql/docs/mysql/db-versions Answer is D upvoted 8 times https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 801 / 803 --- PAGE 2 --- Profess\"onal Cloud Arch\"tect Exam - Free Actual Q&As, Page 1 | ExamTop\"cs 19.12.2024 13:49 crypt0 Highly Voted 5 years, 1 month ago I would tend to answer B \"Second Generation instances support MySQL 5.6 or 5.7,\" https://cloud.google.com/sql/docs/mysql/features upvoted 14 times chiar 5 years, 1 month ago I agree, the answer is B upvoted 7 times addy007 5 years ago Downgrading is not supported. Seems C is the right choice. https://dev.mysql.com/doc/refman/8.0/en/downgrading.html upvoted 4 times xps 4 years, 7 months ago Downgrade is possible from 5.7 to 5.6, which is in the same major version. So downgrade from 5.8 to 5.7 makes sense. Containerize the java applications require to build kubernetes infrastructures in the on-premise environment, it's not in the plan. So the answer goes to B. upvoted 3 times 6a8c7ad Most Recent 4 months, 1 week ago It’s not D. Says on prem change prior to migrate. Definitely not D. upvoted 1 times jcataluna 1 year ago Selected Answer: B MySQL 5.8 not supported on Cloud SQL upvoted 1 times SAMBIT 2 years, 9 months ago Replace RabbitMQ with pub sub …A https://docs.devicewise.com/Content/Products/GatewayDevelopersGuide/CloudConnectors/GoogleCloud/GoogleCloudPlatform.htm upvoted 3 times ABO_Doma 3 years ago Selected Answer: D Containerizing the existing applications ensures efficient use of resources. This activity the business requirement “optimize architecture for performance in the cloud”. As a precursor to Cloud migration, you could convert the microservices to containers and host them on GKE on-prem: https://cloud.google.com/anthos/gke/docs/on-prem/overview which also makes it very easy for you to migrate to Cloud. GKE on-prem is hybrid cloud software that brings Google Kubernetes Engine (GKE) to on-premises data centres. With GKE on-prem, you can create, manage, and upgrade Kubernetes clusters in your on-premises environment. upvoted 10 times didek1986 3 years ago D read business req. upvoted 2 times kvenkatasudhakar 3 years ago Cloud SQL supports MySQL 5.6, 5.7 and 8.0 and the current onprem version is MySQL 5.8. So downgrade from 5.8 to 5.7 is the right answer (D). upvoted 1 times phantomsg 3 years ago Selected Answer: D 'D' as it matches the requirement - Improve business agility and speed of innovation through rapid provisioning of new resources. Among the choices, containerizing microservices will allow the company to deploy and scale services independantly. upvoted 4 times joe2211 3 years ago Selected Answer: D vote D upvoted 1 times https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 802 / 803 --- PAGE 3 --- Profess\"onal Cloud Arch\"tect Exam - Free Actual Q&As, Page 1 | ExamTop\"cs 19.12.2024 13:49 kopper2019 3 years, 5 months ago hey guys new Qs posted as of July 12th, 2021, All 21 new Qs in Question #152 upvoted 3 times vishwassahu 3 years, 3 months ago it seems 21 new questions are deleted upvoted 2 times victory108 3 years, 5 months ago D. Containerize the micro-services and host them in Google Kubernetes Engine. upvoted 6 times MamthaSJ 3 years, 5 months ago Answer is D upvoted 4 times wilwong 3 years, 5 months ago Answer is D upvoted 2 times getzsagar 3 years, 7 months ago One important Update related to case study - Date - 27-04-2021 Right answer is option D --- Case Study for Dress4win is updated, MYSQL version 5.7 is mentioned in the case study and not 5.8 as given in here. This makes option B invalid. Right answer is option D. In the exam I saw option B was still given to confuse people, but in the case study they mentioned the MYSQL version 5.7 and not 5.8. So despite of being confident about the case studies, ensure that you read it thoroughly even during the exam. Time is given sufficient enough. upvoted 7 times ansh0692 3 years, 8 months ago Answer is D A: If you are expecting to \"install\" pub/sub locally and not connect to the hosted GCP service, you cannot use pub/sub, if it is okay for you to use hosted pub/sub and then do the rest of the processing on prem but you won't get a readily available system or you'll have to integrate a lot of things. B: 5.8 is basically 8.0 and it is supported C: Best practice is to find the predefined types on GCVPi eaws icnlgo spea gteo 1th oeu pt hoyf s1i cpaalg seesr.ver spec and not the oth Br e ow r s e w a a tle y as a t 5 r 0 o % u to n in d c . rease passing rate upvoted 4 times Viewing questions 1-278 out of 278 questions Ausias18 3 years, 8 months ago Answer is D upvoted 5 times https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 803 / 803",
      "page_number": 1,
      "source_file": "Questions_41.pdf",
      "case_study_info": "For this question, refer to the Dress4Win case study. You want to ensure that your on-premises architecture meets business requirements before you migrate your solution. What change in the on-premises architecture should you make? A. Replace RabbitMQ with Google Pub/Sub. B. Downgrade MySQL to v5.7, which is supported by Cloud SQL for MySQL. C. Resize compute resources to match predeKned Compute Engine machine types. D. Containerize the micro-services and host them in Google Kubernetes Engine. chiar Highly Voted 5 years, 1 month ago Be careful, because in the case study that you can find in google website MySQL version is 5.7 https://cloud.google.com/certification/guides/cloud-architect/casestudy-dress4win-rev2 upvoted 20 times jasim21 3 years, 8 months ago cloud SQL support MySQL 5.7 https://cloud.google.com/sql/docs/mysql/db-versions Answer is D upvoted 8 times https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 801 / 803 --- PAGE 2 --- Profess\"onal Cloud Arch\"tect Exam - Free Actual Q&As, | ExamTop\"cs 19.12.2024 13:49 crypt0 Highly Voted 5 years, 1 month ago I would tend to answer B \"Second Generation instances support MySQL 5.6 or 5.7,\" https://cloud.google.com/sql/docs/mysql/features upvoted 14 times chiar 5 years, 1 month ago I agree, the answer is B upvoted 7 times addy007 5 years ago Downgrading is not supported. Seems C is the right choice. https://dev.mysql.com/doc/refman/8.0/en/downgrading.html upvoted 4 times xps 4 years, 7 months ago Downgrade is possible from 5.7 to 5.6, which is in the same major version. So downgrade from 5.8 to 5.7 makes sense. Containerize the java applications require to build kubernetes infrastructures in the on-premise environment, it's not in the plan. So the answer goes to B. upvoted 3 times 6a8c7ad Most Recent 4 months, 1 week ago It’s not D. Says on prem change prior to migrate. Definitely not D. upvoted 1 times jcataluna 1 year ago Selected Answer: B MySQL 5.8 not supported on Cloud SQL u",
      "confidence_score": 0.85,
      "claude_answer": "",
      "claude_reasoning": "",
      "topic": "Case Study",
      "latest_date": "3 days ago"
    }
  ],
  "community_comments": [
    {
      "question_id": "Q1_1",
      "username": "community",
      "content": "shandy Highly Voted 2 months, 4 weeks ago D is the answer because HTTP(S) load balancer can direct traffic reaching a single IP to different backends based on the incoming URL. A is not correct because configuring a new load balancer would require a new or different SSL and DNS records which conflicts with the requirements to keep the same SSL and DNS records. B is not correct because it goes against the requirements. The company wants t",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q5_2",
      "username": "community",
      "content": "Eroc Highly Voted 2 months, 4 weeks ago This question could go either way for A or B. But Big Query was designed with this in mind, according to numerous Google presentation and videos. Cloud Datastore is a NoSQL database (https://cloud.google.com/datastore/docs/concepts/overview) Cloud Storage does not have an SQL interface. The previous two sentences eliminate options C and D. So I'd pick \"A\". upvoted 35 times",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q8_3",
      "username": "community",
      "content": "NapoleonBorntoparty Highly Voted 2 months, 4 weeks ago This is talking about the APPLICATION not the infrastructure, therefore I believe we should focus on the APP-side of things: 1. port the app to app engine for content delivery 2. add monitoring for troubleshooting 3. use a CI/CD workflow for continuous delivery w/testing for a stable application so, for me: A, C and E sh",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q12_4",
      "username": "community",
      "content": "jackdbd Highly Voted 2 months, 4 weeks ago It's A. AppEngine spins up new containers automatically according to the load. During peak traffic, HTTP requests originated by the same user could be served by different containers. Given that the variable `sessions` is recreated for each container, it might store different data. The problem here is that this Flask app is stateful. The `sessions` variable is the state of this app. And stateful v",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q15_5",
      "username": "community",
      "content": "dummyemailforexam Highly Voted 4 years, 7 months ago A. This is GCP exam. They will always promote their services. Not a third party solution. upvoted 113 times Ziegler 4 years, 6 months ago Remember that agent is only required for non cloud based resources.",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q18_71",
      "username": "community",
      "content": "sdsdfasdf4 Highly Voted 3 years, 12 months ago The easiest way would be to create template from --source-instance, and then create MIG, but it is not listed here, also you cannot create a MIG from image directly, you need a template, so answer is C (image -> template -> mig). upvoted 30 times 6721sora 2 years, 3 months ago",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q20_72",
      "username": "community",
      "content": "AWS56 Highly Voted 3 years, 5 months ago Agree B upvoted 24 times kumarp6 2 years, 7 months ago Yes B it is upvoted 2 times",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q2_73",
      "username": "community",
      "content": "AWS56 Highly Voted 4 years, 11 months ago Agree with A upvoted 26 times heretolearnazure 1 year, 3 months ago Sharding database will reduce latency",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q6_74",
      "username": "community",
      "content": "AWS56 Highly Voted 4 years, 11 months ago Agree D upvoted 20 times tartar 4 years, 4 months ago D is ok upvoted 5 times",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q8_75",
      "username": "community",
      "content": "jcmoranp Highly Voted 4 years, 1 month ago post mortem always includes log analysis, answer is C upvoted 65 times Sur_Nikki 7 months, 2 weeks ago Thanks for the info upvoted 1 times",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q10_76",
      "username": "community",
      "content": "AWS56 Highly Voted 4 years, 5 months ago Agree A upvoted 26 times nitinz 3 years, 3 months ago A is correct",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q13_77",
      "username": "community",
      "content": "Googler2 Highly Voted 4 years, 8 months ago It can't be -A - VPC Network Peering only allows private RFC 1918 connectivity across two Virtual Private Cloud (VPC) networks. In this example is one VPC with on-premise network https://cloud.google.com/vpc/docs/vpc-peering It is not definitely - B - Can't be",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q16_78",
      "username": "community",
      "content": "KouShikyou Highly Voted 4 years, 8 months ago Could you please help clarify? I think B is correct. It looks like table will be deleted with option A. https://cloud.google.com/bigquery/docs/managing-tables#updating_a_tables_expiration_time When you delete a table, any data in the table is also deleted. To automatically delete tables after a specified period of time, set the default table",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q18_79",
      "username": "community",
      "content": "Unfaithful Highly Voted 2 years, 5 months ago Answer: A Support: How does Horizontal Pod Autoscaler work with Cluster Autoscaler? Horizontal Pod Autoscaler changes the deployment's or replicaset's number of replicas based on the current CPU load. If the load increases, HPA will create ne",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q9_83",
      "username": "community",
      "content": "Googler2 Highly Voted 4 years, 8 months ago D- reasons: 1.-Cloud Audit Logs maintains audit logs for admin activity, data access and system events. BIGQUERY is automatically send to cloud audit log functionality. 2.- In the filter you can filter relevant BigQuery Audit messages, you can express filters as part",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q12_84",
      "username": "community",
      "content": "crypt0 Highly Voted 3 years, 8 months ago Why is it not answer B? upvoted 42 times https:",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q15_85",
      "username": "community",
      "content": "Sebatian Highly Voted 5 years ago It should be A. The question requires that user from each country can only view a specific data set, so BQ dataViewer cannot be assigned at project level. Only A could limit the user to query and view the data that they are supposed to be allowed to. upvoted 61 times jits1984 1 year, 8 months ago",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q19_86",
      "username": "community",
      "content": "OSNG Highly Voted 4 years ago B is correct. WHY NOT OTHERS. A: is wrong Local SSD in non-persistent therefore cannot be used for session state (as questions also need to save data for users who are offline for several days). C: Again Loc",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q5_88",
      "username": "community",
      "content": "shandy Highly Voted 5 years ago Option A is Correct. https://cloud.google.com/cdn/docs/caching#cache-keys upvoted 23 times tartar 4 years, 4 months ago A is ok",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q10_90",
      "username": "community",
      "content": "KouShikyou Highly Voted 3 years, 8 months ago I think B is correct. Because GAE supports service version control and A/B test. Is my understanding correct? upvoted 60 times kumarp6 2 years, 7 months ago",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q17_93",
      "username": "community",
      "content": "crypt0 Highly Voted 5 years, 1 month ago Why not using Ingress? (A) upvoted 28 times techalik 4 years ago I think A is OK:",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q20_94",
      "username": "community",
      "content": "victory108 Highly Voted 2 years, 1 month ago B. Create an HTTPS load balancer with URL maps. upvoted 14 times betiy Highly Voted 3 years, 5 months ago URL paths supported only in HTTP(S) Load balancing",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q3_95",
      "username": "community",
      "content": "bigob4ek Highly Voted 3 years, 7 months ago Answer is B You should use exponential backoff to retry your requests when receiving errors with 5xx or 429 response codes from Cloud Storage. https://cloud.google.com/storage/docs/request-rate upvoted 41 times nitinz 2 years, 3 month",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q10_98",
      "username": "community",
      "content": "AWS56 Highly Voted 4 years, 11 months ago Agree C upvoted 23 times desertlotus1211 Most Recent 3 weeks, 2 days ago Selected Answer: B",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q12_99",
      "username": "community",
      "content": "hiteshrup Highly Voted 3 years ago A dedicated memset is always better than shared until cost-effectiveness specify in the exam as objective. So Option C and D are ruled out. From A and B, Option B is sending and updating query every minutes which is over killing. So reasonable option left with A which balance performance and cost.",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q14_100",
      "username": "community",
      "content": "JoeShmoe Highly Voted 4 years, 7 months ago Answer is B upvoted 32 times Smart Highly Voted 4 years, 3 months ago B is correct. More appropriately: https://cloud.google.com/solutions/reliable-task-scheduling-compute-engine upvoted 30 times",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q16_101",
      "username": "community",
      "content": "KouShikyou Highly Voted 5 years, 2 months ago https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 276 / 803",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q19_102",
      "username": "community",
      "content": "exampanic Highly Voted 4 years, 11 months ago I believe the answer is B. \"Pub/Sub doesn't provide guarantees about the order of message delivery. Strict message ordering can be achieved with buffering, often using Dataflow.\" https://cloud.google.com/solutions/data-lifecycle-cloud-platform upvoted 68 times",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q2_103",
      "username": "community",
      "content": "kopper2019 Highly Voted 3 years, 5 months ago Ans ) C , Migrate for Compute Engine organizes groups of VMs into Waves. After understanding the dependencies of your applications, create runbooks that contain groups of VMs and begin your migration! https://cloud.google.com/migrate/compute-engine/docs/4.5/how-to/migrate-on-premises-to-gcp/overview",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q4_104",
      "username": "community",
      "content": "VishalB Highly Voted 2 years, 11 months ago Correct Ans : D Since the Traffic is TCP, Ans A & C gets eliminated as HTTPS load balance is not supported. B - File storage system is Cloud Firestore which do not give full control, hence eliminated. D - Unmanaged instance group with network load b",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q7_105",
      "username": "community",
      "content": "kopper2019 Highly Voted 3 years, 5 months ago Ans ) D , Reason : high throughput via internal IPs upvoted 67 times ShadowLord 2 years, 4 months ago This is tricky questions , it can be achieved by C and D ... Multiple Computes and",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q12_107",
      "username": "community",
      "content": "kopper2019 Highly Voted 2 years, 11 months ago Ans ) A . upvoted 57 times https:",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q14_108",
      "username": "community",
      "content": "kopper2019 Highly Voted 2 years, 11 months ago Ans) C and D Cloud SQL. If you use Cloud SQL, the fully managed Google Cloud MySQL database, you should enable automated backups and binary logging for your Cloud SQL instances. This allows you to perform a point-in-time recovery, which restores your database from a backup and recovers it to a fresh Cloud SQL instance",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q1_110",
      "username": "community",
      "content": "kopper2019 Highly Voted 3 years, 5 months ago A. App Engine upvoted 36 times arsav Highly Voted 3 years, 4 months ago Answer should be A as only with App Engine we have a default service account which allows the user to deploy the changes per project. for GKE we may have to c",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q3_111",
      "username": "community",
      "content": "pamepadero Highly Voted 3 years, 5 months ago B is the answer. https://cloud.google.com/blog/products/it-ops/best-practices-for-optimizing-your-cloud-costs Schedule VMs to auto start and stop: The benefit of a platform like Compute Engine is that you only pay for the compute resources that you use.",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q8_113",
      "username": "community",
      "content": "victory108 Highly Voted 2 years, 11 months ago D. Set an Organization Policy with a constraint on constraints/compute.vmExternalIpAccess. List the approved instances in the allowedValues list. upvoted 24 times AnilKr Highly Voted 2 years, 10 months ago Ans - D, https://c",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q10_114",
      "username": "community",
      "content": "nohel Highly Voted 3 years, 5 months ago Answer is B when you create a firewall rule there is an option for firewall rule logging on/off. It is set to off by default. To get firewall insights or view the logs for a specific firewall rule you need to enable logging while creating the rule or you can enable it by editing that rule.",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q14_116",
      "username": "community",
      "content": "XDevX Highly Voted 3 years, 5 months ago IMHO the correct answer is d) opportunistic mode, not c) proactive mode. The requirement is not to update any running instances. see: https://cloud.google.com/compute/docs/instance-groups/rolling-out-updates-to-m",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q19_118",
      "username": "community",
      "content": "VishalB Highly Voted 3 years, 4 months ago Correct Answer: A - IP Should not overlap so applying new IP address is the solution upvoted 42 times zanfo 2 years, 9 months ago",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q1_7",
      "username": "community",
      "content": "[Removed] Highly Voted 2 months, 4 weeks ago I spent all morning researching this question. I just popped over and took the GCP Practice exam on Google's website and guess what... this question was on it word for word, but it had slightly different answers, but not by much here is what I learned. The correct answer is 100% A / D and here is why. On the sample question, the \"F\" option is gone. \"A\" is there but slightly reworked, it now says:",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q6_9",
      "username": "community",
      "content": "Eroc Highly Voted 2 months, 4 weeks ago \"A\" and \"B\" wouldn't turn the VMs on or off, it would jsut prevent traffic. \"C\" would turn them off if the health check is configured to terminate the VM is it fails. \"D\" is the start of a pseudo health check without any logic, so it also isn't an answer because it is like \"A\" and \"B\". Correct Answer: \"C\" upvoted 35 ti",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q8_10",
      "username": "community",
      "content": "kalschi Highly Voted 2 months, 4 weeks ago A - If client library was not installed, the python scripts won't run - since the question states the script reports \"cannot connect\" - the client library must have been installed. so it's B or C. B - https://cloud.google.com/bigquery/docs/authorization an access scope is how your client application retrieve access_token with access permission in OAuth whe",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q5_16",
      "username": "community",
      "content": "victory108 Highly Voted 3 years, 5 months ago B. Google Cloud Bigtable upvoted 12 times https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 45 / 803",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q7_17",
      "username": "community",
      "content": "Eroc Highly Voted 5 years, 1 month ago All four are correct answers. Google has built in cron job schduling with Cloud Schedule, so that would place \"D\" behind \"C\" in Google's perspective. Google also has it's own lifecycle management command line prompt gcloud lifecycle so \"A\" or \"B\" could be used. JSON is slightly https://www.examtop\"cs.com/exams/google/pro",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q12_19",
      "username": "community",
      "content": "shandy Highly Voted 5 years ago Answer is C because persistent disk performance is based on the total persistent disk capacity attached to an instance and the number of vCPUs that the instance has. Incrementing the persistent disk capacity will increment its throughput and IOPS, which in turn improve the performance of MySQL. upvoted 68 times",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q16_21",
      "username": "community",
      "content": "jcmoranp Highly Voted 5 years, 1 month ago resilience test is not about load, is about terminate resources and service not affected. Think it's B. The best for resilience in to introduce chaos in the infraestructure upvoted 90 times",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q2_23",
      "username": "community",
      "content": "ghitesh Highly Voted 4 years, 11 months ago Question Statement: You want to adjust your test and deployment procedures to avoid this problem in the future So based on this, I think the option \"C\" is correct, since it is the only one talking about doing changes in the test environment. upvoted 82 times",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q10_26",
      "username": "community",
      "content": "JoeShmoe Highly Voted 5 years, 1 month ago D is correct and best practice for long term log storage upvoted 149 times AndreaMa 5 months, 3 weeks ago same for me. The best approach for the long time log is to export it from monitoring to Cloud Storage Archival type upvoted 1 times",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q16_28",
      "username": "community",
      "content": "ghitesh Highly Voted 4 years, 11 months ago B. https://cloud.google.com/iam/docs/roles-audit-logging#scenario_external_auditors upvoted 98 times rockstar9622 4 years, 11 months ago b) seems correct",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q5_31",
      "username": "community",
      "content": "rsamant Highly Voted 3 years, 6 months ago it should be A .. helm is needed for \"Deploy application bundles using dynamic templates\" Load Balancing should be part of GKE Already upvoted 66 times raf2121 3 years, 3 months ago",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q11_33",
      "username": "community",
      "content": "shandy Highly Voted 5 years ago D. refer to target filtering. https://cloud.google.com/solutions/best-practices-vpc-design upvoted 36 times tartar 4 years, 4 months ago D is ok",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q19_36",
      "username": "community",
      "content": "amxexam Highly Voted 3 years, 3 months ago Let's go with option elimination A. Log in to a server, and iterate on the fix locally >> Long step, hence eliminate B. Revert the source code change and rerun the deployment pipeline",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q2_37",
      "username": "community",
      "content": "AWS56 Highly Voted 5 years ago https://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations I will stick with C upvoted 27 times CamiloJrJr 3 weeks, 5 days ago",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q7_39",
      "username": "community",
      "content": "KouShikyou Highly Voted 5 years, 1 month ago I am not sure about this one. D works if SSL client authentication is enabled. C works as well if client encrypts message with private key and server decrypt with public key. I prefer C. upvoted 37 times JoeShmoe 5 years, 1 month ago",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q16_42",
      "username": "community",
      "content": "ffk Highly Voted 5 years, 1 month ago A is correct https://cloud.google.com/shell/docs/how-cloud-shell-works Cloud Shell provisions 5 GB of free persistent disk storage mounted as your $HOME directory on the virtual machine instance. This storage is on a per-user basis and is available across projects. Unlike the instance itself, this storage does",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q19_43",
      "username": "community",
      "content": "AWS56 Highly Voted 4 years, 11 months ago Cloud VPN supports unto 3 Gbps where as Interconnect can support unto 100 gbps... I'll go with A upvoted 45 times tartar 4 years, 4 months ago A is ok",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q1_44",
      "username": "community",
      "content": "ehgm Highly Voted 2 years, 11 months ago Sustained are automatic discounts for running specific GCE a significant portion of the billing month: https://cloud.google.com/compute/docs/sustained-use-discounts Committed is for workloads with predictable resource needs between 1 year or 3 year, discount is up to 57% for most resources: https://cloud.google.com/compute/docs/instances/signing-up-committed-use-discounts",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q4_45",
      "username": "community",
      "content": "Googler2 Highly Voted 4 years, 8 months ago I believe the best answer is D, because the tagging is a best practice that is recommended on Jenkins/Spinnaker to deploy the right code and prevent accidentally (or intentionally) push of wrong code to production environments. See https://stackify.com/continuous-delivery-git-jenkins/ upvoted 59 times",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q7_46",
      "username": "community",
      "content": "Narinder Highly Voted 2 years, 11 months ago C, is the correct answer. As per the requirement linux expert would need access to VM to troubleshoot the issue. With health check enabled, old VM will be terminated as soon as health-check fails for the VM and new VM will be auto-created. So, this situation will prevent linux expert to troubleshoot the issue. Had it been the case that stack-drover logging is enabled and the expert just want to v",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q10_47",
      "username": "community",
      "content": "rishab86 Highly Voted 3 years, 6 months ago Link : https://cloud.google.com/security/compliance/pci-dss Clearly mention GKE as PCI DSS-Compliant but not all GCP service are PCI DSS-Compliant so answer is definitely C. upvoted 46 times Mikado211 2 years, 4 months ago In 2022, GCP is now fully PCI-DSS compliant",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q12_48",
      "username": "community",
      "content": "JohnWick2020 Highly Voted 3 years, 8 months ago Answer is B: Keynotes from question: 1- On-premise data sources 2- Unfit data; not well maintained and degraded 3- Google-recommended best practice to \"detect anomalies\" <<-Very important.",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q15_49",
      "username": "community",
      "content": "passnow Highly Voted 5 years ago The effective policy for a resource is the union of the policy set at that resource and the policy inherited from its parent.https://cloud.google.com/iam/docs/resource-hierarchy-access-control upvoted 31 times ghadxx Highly Voted 2 years, 10 months ago You can set IAM policies at the level of",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q17_50",
      "username": "community",
      "content": "newbie2020 Highly Voted 4 years, 10 months ago https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 137 / 803",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q1_51",
      "username": "community",
      "content": "jcmoranp Highly Voted 5 years, 1 month ago Correct A, you have to recreate the indexes upvoted 30 times nitinz 3 years, 9 months ago A, if index is missing then create it.",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q3_52",
      "username": "community",
      "content": "Eroc Highly Voted 4 years, 7 months ago Groups are better for management that non-groups so A and B are eliminated. Keeping the the instances in the same project will help maintain https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 143 / 803",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q6_53",
      "username": "community",
      "content": "MyPractice Highly Voted 4 years, 11 months ago Agree with D - \"When to choose the flexible environment\" \"Accesses the resources or services of your Google Cloud project that reside in the Compute Engine network.\" https://cloud.google.com/appengine/docs/the-appengine-environments upvoted 54 times",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q16_56",
      "username": "community",
      "content": "ffk Highly Voted 5 years, 1 month ago A is correct. B is funny upvoted 47 times AmitAr 2 years, 7 months ago",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q19_57",
      "username": "community",
      "content": "RitwickKumar Highly Voted 1 year, 10 months ago https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 159 / 803",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q3_58",
      "username": "community",
      "content": "jcmoranp Highly Voted 5 years, 1 month ago Correct answer is B upvoted 44 times tartar 4 years, 4 months ago B is ok",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q11_61",
      "username": "community",
      "content": "MeasService Highly Voted 4 years, 8 months ago It has to be B. gcloud for creating cluster and kubectl for creating deployment upvoted 54 times KouShikyou Highly Voted 4 years, 8 months ago May I ask why C is correct? I thought B was correct.",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q13_62",
      "username": "community",
      "content": "KouShikyou Highly Voted 5 years, 1 month ago B is correct. upvoted 46 times kumarp6 4 years, 1 month ago Yes it is",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q15_63",
      "username": "community",
      "content": "abirroy Highly Voted 2 years, 3 months ago Selected Answer: A A. Cloud Functions - managed service scales down to 0 B. Compute Engine - not a managed service C. Google Kubernetes Engine - not a managed service and wont scale down to 0 D. AppEngine flexible environment - managed service but wont scale down to 0",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    },
    {
      "question_id": "Q18_64",
      "username": "community",
      "content": "shashu07 Highly Voted 4 years ago Correct Answer: A https://www.examtop\"cs.com/exams/google/profess\"onal-cloud-arch\"tect/custom-v\"ew/ Sayfa 178 / 803",
      "timestamp": "",
      "vote_count": 0,
      "vote_type": ""
    }
  ]
}